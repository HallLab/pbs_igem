{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 6: Run Interactions\n",
    "\n",
    "Documentation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import igem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the data folder\n",
    "path = Path().resolve()\n",
    "path_data = path / \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 06_00: Processing identified interaction data (GE.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 401,736 observations of 5 variables\n",
      "Start with: 401736 interactions\n"
     ]
    }
   ],
   "source": [
    "# Read Moldel (we need to clean interactions that is not in coluns list)\n",
    "df_model = igem.epc.load.from_csv(str(path_data) + \"/step_02_06_Models.csv\") \n",
    "print(f\"Start with: {len(df_model)} interactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Running colfilter\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWARNING: 5 variables need to be categorized into a type manually\u001b[0m\n",
      "Keeping 2 of 5 variables:\n",
      "\t0 of 0 binary variables\n",
      "\t0 of 0 categorical variables\n",
      "\t0 of 0 continuous variables\n",
      "\t2 of 5 unknown variables\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Keep only interactions terms\n",
    "df_model = igem.epc.modify.colfilter(\n",
    "    df_model,\n",
    "    only=['field_name_1', 'field_name_2']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 06_01: Process Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if columns exist in DataFrame\n",
    "def columns_exist(df, cols):\n",
    "        return all(col in df.columns for col in cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the groups\n",
    "list_covariates = ['RIDAGEYR', 'RIAGENDR', 'RIDRETH1', 'BMXBMI', 'Cycle']\n",
    "list_outcomes = ['LBDLDL_N', 'LBXTC_N', 'LBXSTR', 'LBDHDL', 'LBXHDD', 'LBDHDD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to collect results\n",
    "df_results_discover_final = pd.DataFrame()\n",
    "df_results_replicate_final = pd.DataFrame()\n",
    "list_results_discover = []\n",
    "list_results_replicate = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to process each Outcome\n",
    "results = []\n",
    "list_outcomes = ['LBDLDL_N'] # DEBUG ONLY\n",
    "# list_outcomes = ['LBDLDL_N', 'LBXTC_N', 'LBXSTR'] # DEBUG ONLY\n",
    "for outcome in list_outcomes:\n",
    "\n",
    "    # Set\n",
    "    count_lt_threshold = 0\n",
    "    count_no_columns = 0\n",
    "    count_same_e = 0\n",
    "\n",
    "    # Read QC Dataset\n",
    "    file_name = str(path_data) + \"/step_05_05/QC_NHANES_\" + outcome + \".pkl\"\n",
    "    df_nhanes = pd.read_pickle(file_name)\n",
    "\n",
    "    # check columns types as Object / Unknowm-Type\n",
    "    igem.epc.describe.summarize(df_nhanes)\n",
    "\n",
    "    # Define the list of exposes\n",
    "    excluded_columns = set(list_covariates + list_outcomes)\n",
    "    list_exposes = [col for col in df_nhanes.columns if col not in excluded_columns]\n",
    "\n",
    "    # Keep only interactions that are in the columns of df_nhanes\n",
    "    # Create a set of df_nhanes columns for quick checking\n",
    "    nhanes_columns = set(df_nhanes.columns)\n",
    "    # filter df_models to keep only interactions where both terms are in df_nhanes columns\n",
    "    df_models_filtered = df_model[df_model.apply(lambda row: row['field_name_1'] in nhanes_columns and row['field_name_2'] in nhanes_columns, axis=1)]\n",
    "    df_models_filtered.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Total Interactions = {len(df_model)} / After sync = {len(df_models_filtered)}\")\n",
    "\n",
    "    # Split Dataset\n",
    "    df_discovery = df_nhanes[df_nhanes['group'] == 'discovery']\n",
    "    df_replicate = df_nhanes[df_nhanes['group'] == 'replication']\n",
    "\n",
    "\n",
    "    for i_mappair in df_models_filtered.index:\n",
    "        # get Exposomes\n",
    "        e1 = df_models_filtered[\"field_name_1\"][i_mappair]\n",
    "        e2 = df_models_filtered[\"field_name_2\"][i_mappair]\n",
    "\n",
    "        # RUN QC over Exposures Subset\n",
    "        # Check if columns exist in the DataFrame\n",
    "        if columns_exist(df_discovery, [e1, e2]):\n",
    "            # create a DataFrame with the columns of interest\n",
    "            v_list = list_covariates + [outcome, e1, e2]\n",
    "            df_exe = df_discovery.loc[:, v_list]\n",
    "            print(f\"Processed with: {e1} and {e2}\")\n",
    "        else:\n",
    "            print(f\"Skipped: {e1} and/or {e2} not found\")\n",
    "            continue\n",
    "\n",
    "        # Drop interactions if Object Type\n",
    "        object_columns = df_exe.select_dtypes(include=['object']).columns\n",
    "        df_exe = df_exe.drop(columns=object_columns)\n",
    "\n",
    "        # Drop all row with any NAN\n",
    "        df_exe = df_exe.dropna()\n",
    "\n",
    "        # Drop Constants Columns\n",
    "        non_constant_columns = df_exe.columns[df_exe.nunique() > 1]\n",
    "        df_exe = df_exe[non_constant_columns]\n",
    "\n",
    "        if len(df_exe) < 200:\n",
    "            count_lt_threshold += 1\n",
    "            continue\n",
    "        if not columns_exist(df_exe, v_list):\n",
    "            count_no_columns += 1\n",
    "            continue\n",
    "        if e1 == e2:\n",
    "            count_same_e += 1\n",
    "            continue\n",
    "        # -- End of QC\n",
    "\n",
    "        # Run the interaction study\n",
    "        Interation_Study = igem.epc.analyze.interaction_study(\n",
    "            data=df_exe,\n",
    "            outcomes=outcome,\n",
    "            interactions=[(e1, e2)],\n",
    "            covariates=list_covariates,\n",
    "            min_n=200,\n",
    "        )\n",
    "\n",
    "        # Keep the results values\n",
    "        list_results_discover.append(\n",
    "            [\n",
    "                Interation_Study.LRT_pvalue.index.levels[2][0],\n",
    "                Interation_Study.LRT_pvalue.index.levels[0][0],\n",
    "                Interation_Study.LRT_pvalue.index.levels[1][0],\n",
    "                Interation_Study.Converged.values[0],\n",
    "                Interation_Study.LRT_pvalue.values[0],\n",
    "                Interation_Study.LRT_pvalue.values[0] * len(df_exe),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Create a DataFrame with the results\n",
    "    df_results_discover = pd.DataFrame(\n",
    "        list_results_discover,\n",
    "        columns=[\n",
    "            \"Outcome\", \"Term1\", \"Term2\", \"Converged\", \"pvalue\", \"Bonfp\"\n",
    "            ],\n",
    "    )\n",
    "\n",
    "    igem.epc.analyze.add_corrected_pvalues(df_results_discover)\n",
    "\n",
    "    # Get a dictionary of phenotype : list of significant variables\n",
    "    df_results_discover_sig = df_results_discover[\n",
    "        df_results_discover['pvalue_fdr'] < 0.1\n",
    "        ]\n",
    "    \n",
    "    df_results_discover_sig.to_csv('test_process.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
