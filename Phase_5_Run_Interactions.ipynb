{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpy2 ModuleSpec(name='rpy2', loader=<_frozen_importlib_external.SourceFileLoader object at 0x352e45ff0>, origin='/Users/andrerico/Works/Projects/pbs_igem/.venv/lib/python3.10/site-packages/rpy2/__init__.py', submodule_search_locations=['/Users/andrerico/Works/Projects/pbs_igem/.venv/lib/python3.10/site-packages/rpy2'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import igem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the data folder\n",
    "path = Path().resolve()\n",
    "path_data = path / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 55,206 observations of 918 variables\n",
      "Start Run Interactions Process with: 55206 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrerico/Works/Projects/pbs_igem/.venv/lib/python3.10/site-packages/igem/epc/clarite/load/load.py:77: DtypeWarning: Columns (442,869) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  return clarite.load.from_csv(filename, index_col, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Read NHANES Data (with medications normalized to LDL and TC)\n",
    "df_nhanes = igem.epc.load.from_csv(\n",
    "    str(path_data) +  \"/step_04_02_nhanes_data_with_medications.csv\",\n",
    "    index_col='ID'\n",
    "    )\n",
    "df_nhanes.index = df_nhanes.index.astype(int)\n",
    "print(f\"Start Run Interactions Process with: {len(df_nhanes)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 992,923 observations of 5 variables\n",
      "Start with: 992923 interactions\n"
     ]
    }
   ],
   "source": [
    "# Read Moldel (we need to clean interactions that is not in coluns list)\n",
    "df_model = igem.epc.load.from_csv(str(path_data) + \"/step_01_05_Models.csv\") \n",
    "print(f\"Start with: {len(df_model)} interactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Running colfilter\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWARNING: 5 variables need to be categorized into a type manually\u001b[0m\n",
      "Keeping 2 of 5 variables:\n",
      "\t0 of 0 binary variables\n",
      "\t0 of 0 categorical variables\n",
      "\t0 of 0 continuous variables\n",
      "\t2 of 5 unknown variables\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Keep only interactions terms\n",
    "df_model = igem.epc.modify.colfilter(\n",
    "    df_model,\n",
    "    only=['field_name_1', 'field_name_2']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now has 213059 interactions after filtering\n"
     ]
    }
   ],
   "source": [
    "# Keep only interactions that are in the columns of df_nhanes\n",
    "# Create a set of df_nhanes columns for quick checking\n",
    "nhanes_columns = set(df_nhanes.columns)\n",
    "# filter df_models to keep only interactions where both terms are in df_nhanes columns\n",
    "df_models_filtered = df_model[df_model.apply(lambda row: row['field_name_1'] in nhanes_columns and row['field_name_2'] in nhanes_columns, axis=1)]\n",
    "print(f\"Now has {len(df_models_filtered)} interactions after filtering\")\n",
    "df_models_filtered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field_name_1</th>\n",
       "      <th>field_name_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LBDLG1LC</td>\n",
       "      <td>ARQ077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LBDLG1LC</td>\n",
       "      <td>ARQ034D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LBXLG1</td>\n",
       "      <td>ARQ077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LBXLG1</td>\n",
       "      <td>ARQ034D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSLG1_N</td>\n",
       "      <td>ARQ077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213054</th>\n",
       "      <td>LBDSZNSI</td>\n",
       "      <td>SMD830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213055</th>\n",
       "      <td>LBDSZNSI</td>\n",
       "      <td>SMD770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213056</th>\n",
       "      <td>LBDSZNSI</td>\n",
       "      <td>SMD800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213057</th>\n",
       "      <td>LBDSZNSI</td>\n",
       "      <td>SMD740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213058</th>\n",
       "      <td>LBDSZNSI</td>\n",
       "      <td>BIXC005K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213059 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       field_name_1 field_name_2\n",
       "0          LBDLG1LC       ARQ077\n",
       "1          LBDLG1LC      ARQ034D\n",
       "2            LBXLG1       ARQ077\n",
       "3            LBXLG1      ARQ034D\n",
       "4           SSLG1_N       ARQ077\n",
       "...             ...          ...\n",
       "213054     LBDSZNSI       SMD830\n",
       "213055     LBDSZNSI       SMD770\n",
       "213056     LBDSZNSI       SMD800\n",
       "213057     LBDSZNSI       SMD740\n",
       "213058     LBDSZNSI     BIXC005K\n",
       "\n",
       "[213059 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Cohorts\n",
    "\n",
    "good = HDL - Have 3 diff types of metrics ()\n",
    "\n",
    "bad = LDL, Total-C and Triglycerides split in Discovery (1999-2008) and Replicate (2009-2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slipt the data into discovery and replicate in bad group \n",
    "cycles_discovery = ['1999-2000', '2001-2002', '2003-2004', '2005-2006', '2007-2008']\n",
    "cycles_replicate = ['2009-2010', '2011-2012', '2013-2014', '2015-2016', '2017-2018']\n",
    "\n",
    "df_nhanes_discovery = df_nhanes[df_nhanes['Cycle'].isin(cycles_discovery)]\n",
    "df_nhanes_replicate = df_nhanes[df_nhanes['Cycle'].isin(cycles_replicate)]\n",
    "\n",
    "df_nhanes_discovery['Cycle'] = pd.Categorical(df_nhanes_discovery['Cycle'], categories=cycles_discovery, ordered=True)\n",
    "df_nhanes_replicate['Cycle'] = pd.Categorical(df_nhanes_replicate['Cycle'], categories=cycles_replicate, ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Interactions Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_covariates = ['RIDAGEYR', 'RIAGENDR', 'RIDRETH1', 'BMXBMI', 'Cycle']\n",
    "list_bad_phenotypes = ['LBDLDL', 'LBXTC', 'LBXSTR']\n",
    "list_good_phenotypes = ['LBDHDL', 'LBXHDD', 'LBDHDD']\n",
    "\n",
    "excluded_columns = set(list_covariates + list_bad_phenotypes + list_good_phenotypes)\n",
    "list_exposes = [col for col in df_nhanes.columns if col not in excluded_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT:\n",
    "\n",
    "#### before run, we need to ajust cholesterol by who use some medication to control.\n",
    "#### How to check if both group has the same fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para verificar se as colunas existem no DataFrame\n",
    "def columns_exist(df, cols):\n",
    "    return all(col in df.columns for col in cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to collect results\n",
    "df_results_discover_final = pd.DataFrame()\n",
    "df_results_replicate_final = pd.DataFrame()\n",
    "list_results_discover = []\n",
    "list_results_replicate = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will only run it for the LDL phenotype to test the script's integrity.\n",
    "\n",
    "Important: we still need to define the rationale for adjusting participants who use medications to control cholesterol.\n",
    "\n",
    "- Nikki and I are evaluating the use of stalin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with: LBDLDL\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Defines Discovery and Replicate groups based on cycles.\n",
    "Aligns both groups to have the same exposure factors.\n",
    "\n",
    "Important: In production, this block is inside the phenotype loop.\n",
    "\"\"\"\n",
    "\n",
    "list_bad_phenotypes = ['LBDLDL',]\n",
    "for i_outcome in list_bad_phenotypes:\n",
    "    print(f\"Start with: {i_outcome}\")\n",
    "\n",
    "    # Filter the DataFrames to keep only the columns of interest\n",
    "    df_nhanes_discovery_exe = df_nhanes_discovery[[i_outcome] + list_covariates + list_exposes].dropna(subset=[i_outcome])\n",
    "    df_nhanes_replicate_exe = df_nhanes_replicate[[i_outcome] + list_covariates + list_exposes].dropna(subset=[i_outcome])\n",
    "\n",
    "    # Sync both DataFrames to have the same Exposure columns\n",
    "    # Drop columns with all NaN values in both DataFrames\n",
    "    df_nhanes_discovery_exe = df_nhanes_discovery_exe.dropna(axis=1, how='all')\n",
    "    df_nhanes_replicate_exe = df_nhanes_replicate_exe.dropna(axis=1, how='all')\n",
    "    # get the common columns\n",
    "    common_columns = df_nhanes_discovery_exe.columns.intersection(df_nhanes_replicate_exe.columns)\n",
    "    # filter both DataFrames to keep only the common columns\n",
    "    df_nhanes_discovery_exe = df_nhanes_discovery_exe[common_columns]\n",
    "    df_nhanes_replicate_exe = df_nhanes_replicate_exe[common_columns]\n",
    "    # check if both groups as the same number of columns\n",
    "    n_discovery_exe = len(df_nhanes_discovery_exe.columns)\n",
    "    n_replicate_exe = len(df_nhanes_replicate_exe.columns)\n",
    "    # Raise an error if the number of columns is different\n",
    "    if n_discovery_exe != n_replicate_exe:\n",
    "        print(f\"Discovery has {n_discovery_exe} columns and Replicate has {n_replicate_exe} columns\")\n",
    "        print(\"Columns in Discovery but not in Replicate:\")\n",
    "        print(set(df_nhanes_discovery_exe.columns) - set(df_nhanes_replicate_exe.columns))\n",
    "        print(\"Columns in Replicate but not in Discovery:\")\n",
    "        print(set(df_nhanes_replicate_exe.columns) - set(df_nhanes_discovery_exe.columns))\n",
    "        print(\"Skipping this outcome\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 are continuous columns: ['LBDLDL', 'RIDAGEYR', 'RIDRETH1', 'BMXBMI', 'ALQ140Q', 'ALQ150', 'AUQ231', 'CBD620', 'CBQ050', 'DBQ197', 'DBQ229', 'DBQ235A', 'DBQ235B', 'DBQ235C', 'DUQ250', 'DUQ260', 'DUQ270Q', 'DUQ272', 'DUQ290', 'DUQ300', 'DUQ310Q', 'DUQ330', 'DUQ340', 'DUQ350Q', 'DUQ352', 'DUQ380A', 'ENQ090', 'GTDSCMMN', 'GTXDRANK', 'HOQ070', 'HOQ080', 'HSQ590', 'LBDFOL', 'LBDIHGSI', 'LBDRBF', 'LBDV4CLC', 'LBDVBFLC', 'LBDVCFLC', 'LBDVDBLC', 'LBDVEBLC', 'LBDVMELC', 'LBDVOXLC', 'LBDVSTLC', 'LBDVTCLC', 'LBDVTOLC', 'LBDVXYLC', 'LBDWBFLC', 'LBDWCFLC', 'LBX2DF', 'LBXBCD', 'LBXBPB', 'LBXCOT', 'LBXIHG', 'LBXNM', 'LBXPFBS', 'LBXPFDE', 'LBXPFDO', 'LBXPFOA', 'LBXPFOS', 'LBXPFSA', 'LBXPFUA', 'LBXPLP', 'LBXRBFSI', 'LBXSF2SI', 'LBXTHG', 'LBXV1D', 'LBXV2A', 'LBXV2P', 'LBXV2T', 'LBXV3B', 'LBXV4C', 'LBXVBF', 'LBXVBM', 'LBXVBZ', 'LBXVCF', 'LBXVCM', 'LBXVCT', 'LBXVDB', 'LBXVDM', 'LBXVDP', 'LBXVEB', 'LBXVFN', 'LBXVIPB', 'LBXVMC', 'LBXVME', 'LBXVNB', 'LBXVOX', 'LBXVST', 'LBXVTC', 'LBXVTE', 'LBXVTO', 'LBXVXY', 'LBXWBF', 'LBXWBM', 'LBXWCF', 'LBXWCM', 'LBXWME', 'OCQ290G', 'OCQ290Q', 'OSQ020A', 'RDD040', 'SLD010H', 'SMD030', 'SMD055', 'SMD057', 'SMD100CO', 'SMD100NI', 'SMD410', 'SMD415A', 'SMD430', 'SMD630', 'SMQ020', 'SMQ040', 'SMQ050Q', 'SMQ077', 'SMQ620', 'SMQ660', 'SMQ664M', 'SMQ664O', 'SMQ670', 'SMQ680', 'SMQ710', 'SMQ720', 'SMQ725', 'SMQ740', 'SMQ750', 'SMQ755', 'SMQ770', 'SMQ780', 'SMQ785', 'SMQ800', 'SMQ817', 'SMQ830', 'SMQ840', 'URXBPH', 'URXCRS', 'URXDAZ', 'URXDEA', 'URXDEE', 'URXDHD', 'URXEQU', 'URXETL', 'URXGNS', 'URXMAL', 'URXNAL', 'URXNO3', 'URXOP1', 'URXOP2', 'URXOP3', 'URXOP6', 'URXOPP', 'URXSCN', 'URXUAB', 'URXUAS', 'URXUAS5', 'URXUBA', 'URXUBE', 'URXUCD', 'URXUCO', 'URXUCR', 'URXUCS', 'URXUHG', 'URXUIO', 'URXUMO', 'URXUP8', 'URXUPB', 'URXUPT', 'URXUSB', 'URXUTL', 'URXUTM', 'URXUTU', 'URXUUR', 'VTQ250A', 'VTQ250B', 'VTQ260B', 'LBXSBU', 'LBXSCA', 'LBXSCR', 'LBXSGL', 'LBXSIR', 'LBXSKSI', 'LBXSPH', 'LBXSTB', 'LBXSUA', 'LBXACR', 'LBDB12SI', 'LBXB12', 'LBXIRN', 'LBXLCC', 'LBXML1', 'LBDTIB']\n",
      "2 are categorical columns: ['Cycle', 'SMD100BR']\n",
      "65 are binary columns: ['RIAGENDR', 'LBD2DFLC', 'LBDCOTLC', 'LBDIHGLC', 'LBDPFBSL', 'LBDPFDEL', 'LBDPFDOL', 'LBDPFOAL', 'LBDPFOSL', 'LBDPFSAL', 'LBDPFUAL', 'LBDSF2LC', 'LBDTHGLC', 'LBDV2ALC', 'LBDVBMLC', 'LBDVBZLC', 'LBDVCMLC', 'LBDVCTLC', 'LBDVDMLC', 'LBDVDPLC', 'LBDVFNLC', 'LBDVIPLC', 'LBDVMCLC', 'LBDVNBLC', 'LBDVTELC', 'LBDWBMLC', 'LBDWCMLC', 'LBDWMELC', 'PHQ020', 'SMD100MN', 'SMQ664C', 'SPQ100', 'URDBPHLC', 'URDDAZLC', 'URDDEALC', 'URDDEELC', 'URDEQULC', 'URDETLLC', 'URDGNSLC', 'URDMALLC', 'URDNO3LC', 'URDOP1LC', 'URDOP2LC', 'URDOP3LC', 'URDOP6LC', 'URDOPPLC', 'URDSCNLC', 'URDUA5LC', 'URDUABLC', 'URDUASLC', 'URDUBALC', 'URDUBELC', 'URDUCDLC', 'URDUCOLC', 'URDUMOLC', 'URDUPBLC', 'URDUSBLC', 'URDUTMLC', 'URDUTULC', 'URDUURLC', 'WHD080M', 'WHD100M', 'LBDACRLC', 'URDUHGLC', 'Gender']\n",
      "43 are columns to drop with constant value: ['sequence', 'DBQ925B', 'DUQ380B', 'DUQ380C', 'DUQ380D', 'LBD4CELC', 'LBDV1ALC', 'LBDV1DLC', 'LBDV1ELC', 'LBDV2CLC', 'LBDV2ELC', 'LBDV2PLC', 'LBDV2TLC', 'LBDV3BLC', 'LBDV4ELC', 'LBDVCBLC', 'LBDVDELC', 'LBDVHELC', 'LBDVTPLC', 'LBX4CE', 'LBXV1A', 'LBXV1E', 'LBXV2C', 'LBXV2E', 'LBXV4E', 'LBXVCB', 'LBXVDE', 'LBXVHE', 'LBXVTP', 'OSQ160B', 'SMQ690A', 'SMQ690B', 'SMQ690C', 'SMQ690D', 'SMQ690E', 'SMQ690F', 'URDUCSLC', 'URDUP8LC', 'WHD080O', 'WHD080P', 'WHD100O', 'WHD100P', 'LBXMR1']\n",
      "================================================================================\n",
      "Running make_continuous\n",
      "--------------------------------------------------------------------------------\n",
      "Set 191 of 258 variable(s) as continuous, each with 11,453 observations\n",
      "================================================================================\n",
      "================================================================================\n",
      "Running make_categorical\n",
      "--------------------------------------------------------------------------------\n",
      "Set 2 of 258 variable(s) as categorical, each with 11,453 observations\n",
      "================================================================================\n",
      "================================================================================\n",
      "Running make_categorical\n",
      "--------------------------------------------------------------------------------\n",
      "Set 65 of 258 variable(s) as categorical, each with 11,453 observations\n",
      "================================================================================\n",
      "================================================================================\n",
      "Running make_categorical\n",
      "--------------------------------------------------------------------------------\n",
      "Set 2 of 258 variable(s) as categorical, each with 11,453 observations\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Performs the categorization of the analysis components. For constant columns, we will eliminate them.\n",
    "\"\"\"\n",
    "\n",
    "def categorize_columns(df):\n",
    "    continuous = []\n",
    "    categorical = []\n",
    "    binary = []\n",
    "    columns_to_drop = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].dropna().unique()\n",
    "        num_unique_values = len(unique_values)\n",
    "        \n",
    "        if num_unique_values == 1:\n",
    "            # add the column to the list of columns to remove\n",
    "            columns_to_drop.append(col)\n",
    "\n",
    "        elif pd.api.types.is_numeric_dtype(df[col]):\n",
    "            if num_unique_values == 2:\n",
    "                # binary.append(col)\n",
    "                continuous.append(col)\n",
    "            else:\n",
    "                continuous.append(col)\n",
    "        else:\n",
    "            if num_unique_values == 2:\n",
    "                binary.append(col)\n",
    "            else:\n",
    "                categorical.append(col)\n",
    "    \n",
    "    return continuous, categorical, binary, columns_to_drop\n",
    "\n",
    "# run the function to categorize the columns\n",
    "continuous_cols, categorical_cols, binary_cols, columns_to_drop = categorize_columns(df_nhanes_discovery_exe)\n",
    "\n",
    "# show the results\n",
    "print(f\"{len(continuous_cols)} are continuous columns: {continuous_cols}\")\n",
    "print(f\"{len(categorical_cols)} are categorical columns: {categorical_cols}\")\n",
    "print(f\"{len(binary_cols)} are binary columns: {binary_cols}\")\n",
    "print(f\"{len(columns_to_drop)} are columns to drop with constant value: {columns_to_drop}\")\n",
    "\n",
    "# remove the columns with only one unique value\n",
    "df_nhanes_discovery_exe.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "df_nhanes_discovery_exe = igem.epc.modify.make_continuous(\n",
    "    df_nhanes_discovery_exe,\n",
    "    only=continuous_cols\n",
    ")\n",
    "\n",
    "df_nhanes_discovery_exe = igem.epc.modify.make_categorical(\n",
    "    df_nhanes_discovery_exe,\n",
    "    only=categorical_cols\n",
    ")\n",
    "\n",
    "df_nhanes_discovery_exe = igem.epc.modify.make_categorical(\n",
    "    df_nhanes_discovery_exe,\n",
    "    only=binary_cols\n",
    ")\n",
    "\n",
    "# Manually set columns\n",
    "df_nhanes_discovery_exe = igem.epc.modify.make_categorical(\n",
    "    df_nhanes_discovery_exe,\n",
    "    only=[\"RIDRETH1\", \"Cycle\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug propose: Select two expose factores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed with: ALQ140Q and ALQ150\n",
      "11453\n",
      "ALQ140Q  -  ALQ150\n",
      "LBDLDL\n",
      "['RIDAGEYR', 'RIAGENDR', 'RIDRETH1', 'BMXBMI', 'Cycle']\n",
      "RIDAGEYR     float64\n",
      "RIAGENDR    category\n",
      "RIDRETH1    category\n",
      "BMXBMI       float64\n",
      "Cycle       category\n",
      "LBDLDL       float64\n",
      "ALQ140Q      float64\n",
      "ALQ150       float64\n",
      "dtype: object\n",
      "         RIDAGEYR RIAGENDR RIDRETH1  BMXBMI      Cycle  LBDLDL  ALQ140Q  \\\n",
      "ID                                                                        \n",
      "41479.0      52.0      1.0      1.0   27.56  2007-2008   121.0      3.0   \n",
      "41485.0      30.0      2.0      2.0   25.99  2007-2008   119.0      NaN   \n",
      "41486.0      61.0      2.0      1.0   31.21  2007-2008   110.0      NaN   \n",
      "41487.0      27.0      1.0      5.0   23.44  2007-2008   105.0      0.0   \n",
      "41489.0      40.0      2.0      1.0   36.59  2007-2008   106.0      3.0   \n",
      "\n",
      "         ALQ150  \n",
      "ID               \n",
      "41479.0     2.0  \n",
      "41485.0     NaN  \n",
      "41486.0     NaN  \n",
      "41487.0     2.0  \n",
      "41489.0     2.0  \n"
     ]
    }
   ],
   "source": [
    "e1 = \"ALQ140Q\"\n",
    "e2 = \"ALQ150\"\n",
    "\n",
    "# Check if columns exist in the DataFrame\n",
    "if columns_exist(df_nhanes_discovery_exe, [e1, e2]):\n",
    "    # create a DataFrame with the columns of interest\n",
    "    df_maintable_exe = df_nhanes_discovery_exe.loc[:, list_covariates + [i_outcome, e1, e2]]\n",
    "    print(f\"Processed with: {e1} and {e2}\")\n",
    "else:\n",
    "    print(f\"Skipped: {e1} and/or {e2} not found\")\n",
    "\n",
    "print(len(df_maintable_exe))\n",
    "print(e1, \" - \", e2)\n",
    "print(i_outcome)\n",
    "print(list_covariates)\n",
    "print(df_maintable_exe.dtypes)\n",
    "print(df_maintable_exe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "InteractionRegression\n",
      "-------------------------\n",
      "Continuous Outcome (family = Gaussian): 'LBDLDL'\n",
      "Using 11,453 of 11,453 observations\n",
      "Regressing 2 variables\n",
      "\t0 binary variables\n",
      "\t0 categorical variables\n",
      "\t2 continuous variables\n",
      "\t0 genotypes variables\n",
      "Processing 1 interactions\n",
      "-------------------------\n",
      "\u001b[32mRunning 1 interactions using 14 processes...\u001b[0m\n",
      "\n",
      "\u001b[32m\tFinished Running 1 interactions\u001b[0m\n",
      "\u001b[32m0 tests had an error\u001b[0m\n",
      "Completed Interaction Study for LBDLDL\n",
      "\n",
      "Completed association study\n"
     ]
    }
   ],
   "source": [
    "Interation_Study = igem.epc.analyze.interaction_study(\n",
    "        data=df_maintable_exe,\n",
    "        outcomes=i_outcome,\n",
    "        interactions=[(e1, e2)],\n",
    "        covariates=list_covariates,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the loop to process all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for terms in df_models_filtered.itertuples():\n",
    "\n",
    "# e1 = terms.field_name_1\n",
    "# e2 = terms.field_name_2\n",
    "# print(f\"Start with: {e1} and {e2}\")\n",
    "\n",
    "e1 = \"URDUP8LC\"\n",
    "e2 = \"OSQ160B\"\n",
    "\n",
    "# Verifica se as colunas e1 e e2 existem no DataFrame\n",
    "if columns_exist(df_nhanes_discovery_exe, [e1, e2]):\n",
    "    # Cria o DataFrame df_maintable_exe apenas se ambas as colunas existirem\n",
    "    df_maintable_exe = df_nhanes_discovery_exe.loc[:, list_covariates + [i_outcome, e1, e2]]\n",
    "    # Faça o processamento necessário com df_maintable_exe\n",
    "    print(f\"Processed with: {e1} and {e2}\")\n",
    "else:\n",
    "    print(f\"Skipped: {e1} and/or {e2} not found\")\n",
    "    ...\n",
    "\n",
    "print(len(df_maintable_exe))\n",
    "\n",
    "# # Run Interation Study\n",
    "# Interation_Study = igem.epc.analyze.interaction_study(\n",
    "#     data=df_maintable_exe,\n",
    "#     outcomes=i_outcome,\n",
    "#     interactions=[(e1, e2)],\n",
    "#     covariates=list_covariates,\n",
    "# )\n",
    "Interation_Study = igem.analyze.interaction_study(\n",
    "        data=df_maintable_exe,\n",
    "        outcomes=i_outcome,\n",
    "        interactions=[(e1, e2)],\n",
    "        covariates=list_covariates,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "#     # Save results in list: outcome/e1/e2/converged/LRT_pvalue/Bonfp\n",
    "#     list_results_discover.append(\n",
    "#         [\n",
    "#             Interation_Study.LRT_pvalue.index.levels[2][0],\n",
    "#             Interation_Study.LRT_pvalue.index.levels[0][0],\n",
    "#             Interation_Study.LRT_pvalue.index.levels[1][0],\n",
    "#             Interation_Study.Converged.values[0],\n",
    "#             Interation_Study.LRT_pvalue.values[0],\n",
    "#             Interation_Study.LRT_pvalue.values[0] * len(df_maintable_exe),\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "# # Create a DataFrame with the results\n",
    "# df_results_discover = pd.DataFrame(\n",
    "#     list_results_discover,\n",
    "#     columns=[\n",
    "#         \"Outcome\", \"Term1\", \"Term2\", \"Converged\", \"LRT_pvalue\", \"Bonfp\"\n",
    "#         ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATORVASTATIN_CALCIUM\", \"SIMVASTATIN\", \"PRAVASTATIN_SODIUM\", \"FLUVASTATIN_SODIUM\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
