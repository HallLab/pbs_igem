{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: Run Interactions\n",
    "\n",
    "Documentation: https://halllab.atlassian.net/wiki/spaces/IGEM/pages/84705288/Phase+5+Run+Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points to check (with Nikki):\n",
    "- Run skewness only to Phenotypes?\n",
    "- Why she run the Survey to ECHO EAWS Analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpy2 ModuleSpec(name='rpy2', loader=<_frozen_importlib_external.SourceFileLoader object at 0x16ba29f30>, origin='/Users/andrerico/Works/Projects/pbs_igem/.venv/lib/python3.10/site-packages/rpy2/__init__.py', submodule_search_locations=['/Users/andrerico/Works/Projects/pbs_igem/.venv/lib/python3.10/site-packages/rpy2'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import igem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the data folder\n",
    "path = Path().resolve()\n",
    "path_data = path / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 55,206 observations of 918 variables\n",
      "Start Run Interactions Process with: 55206 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrerico/Works/Projects/pbs_igem/.venv/lib/python3.10/site-packages/igem/epc/clarite/load/load.py:77: DtypeWarning: Columns (442,869) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  return clarite.load.from_csv(filename, index_col, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Read NHANES Data (with medications normalized to LDL and TC)\n",
    "df_nhanes = igem.epc.load.from_csv(\n",
    "    str(path_data) +  \"/step_04_02_nhanes_data_with_medications.csv\",\n",
    "    index_col='ID'\n",
    "    )\n",
    "df_nhanes.index = df_nhanes.index.astype(int)\n",
    "print(f\"Start Run Interactions Process with: {len(df_nhanes)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 992,923 observations of 5 variables\n",
      "Start with: 992923 interactions\n"
     ]
    }
   ],
   "source": [
    "# Read Moldel (we need to clean interactions that is not in coluns list)\n",
    "df_model = igem.epc.load.from_csv(str(path_data) + \"/step_01_05_Models.csv\") \n",
    "print(f\"Start with: {len(df_model)} interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session for processing identified interaction data (GE.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Running colfilter\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWARNING: 2 variables need to be categorized into a type manually\u001b[0m\n",
      "Keeping 2 of 2 variables:\n",
      "\t0 of 0 binary variables\n",
      "\t0 of 0 categorical variables\n",
      "\t0 of 0 continuous variables\n",
      "\t2 of 2 unknown variables\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Keep only interactions terms\n",
    "df_model = igem.epc.modify.colfilter(\n",
    "    df_model,\n",
    "    only=['field_name_1', 'field_name_2']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: A classification was performed to identify the fields in NHANES that were exposure factors, and we used these selected fields to search for relationships in IGEM.\n",
    "\n",
    "With Nikki joining the project, she helped refine this list of exposure factors using the data filtered in GE.filter. The search for data in NHANES utilized the list of relevant exposures evaluated by Nikki, which is more restricted.\n",
    "\n",
    "Therefore, the code below will retain interactions only if both terms are present in df_nhanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now has 213059 interactions after filtering\n"
     ]
    }
   ],
   "source": [
    "# Keep only interactions that are in the columns of df_nhanes\n",
    "# Create a set of df_nhanes columns for quick checking\n",
    "nhanes_columns = set(df_nhanes.columns)\n",
    "# filter df_models to keep only interactions where both terms are in df_nhanes columns\n",
    "df_models_filtered = df_model[df_model.apply(lambda row: row['field_name_1'] in nhanes_columns and row['field_name_2'] in nhanes_columns, axis=1)]\n",
    "print(f\"Now has {len(df_models_filtered)} interactions after filtering\")\n",
    "df_models_filtered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Cohorts to LDL, TC and Triglycerides\n",
    "\n",
    "LDL, Total-C and Triglycerides split in Discovery (1999-2008) and Replicate (2009-2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The fields for LDL and Total Cholesterol have been adjusted to account for participants who use any medication to control cholesterol levels. This adjustment is documented in Phase 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_covariates = ['RIDAGEYR', 'RIAGENDR', 'RIDRETH1', 'BMXBMI', 'Cycle']\n",
    "list_phenotypes_wo_adj = ['LBDLDL', 'LBXTC']\n",
    "list_phenotypes = ['LBDLDL_N', 'LBXTC_N', 'LBXSTR', 'LBDHDL', 'LBXHDD', 'LBDHDD']\n",
    "\n",
    "# Define the list of exposes\n",
    "excluded_columns = set(list_covariates + list_phenotypes + list_phenotypes_wo_adj)\n",
    "list_exposes = [col for col in df_nhanes.columns if col not in excluded_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if columns exist in DataFrame\n",
    "def columns_exist(df, cols):\n",
    "    return all(col in df.columns for col in cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to collect results\n",
    "df_results_discover_final = pd.DataFrame()\n",
    "df_results_replicate_final = pd.DataFrame()\n",
    "list_results_discover = []\n",
    "list_results_replicate = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run ExE Interaction Analysis to LDL Phenotype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines Discovery and Replicate groups based on cycles.\n",
    "Aligns both groups to have the same exposure factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with: LBDLDL_N\n"
     ]
    }
   ],
   "source": [
    "# Note: In production, this block is inside the phenotype loop.\n",
    "list_phenotypes = ['LBDLDL_N',]\n",
    "for i_outcome in list_phenotypes:\n",
    "    print(f\"Start with: {i_outcome}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  The sequence of instructions below is part of the loop initiated above. \n",
    "       For development and debugging purposes, the chain has been broken down.\n",
    "\n",
    "The following code divides the NHANES data into two groups: discovery and replication. \n",
    "\n",
    "The discovery group consists of data from earlier cycles, while the replication group consists of data from later cycles.\n",
    "\n",
    "For both df_nhanes_discovery and df_nhanes_replicate, the Cycle column is converted to a categorical type with a specified order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip if the outcome is HDL-c / This will split in 3 cohorts\n",
    "\n",
    "Check: https://halllab.atlassian.net/wiki/spaces/IGEM/pages/62619672/Different+HDL+Cholesterol+Codes+in+NHANES+LBDHDL+LBXHDD+LBDHDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if i_outcome in ['LBDHDL', 'LBXHDD', 'LBDHDD']:\n",
    "    ...\n",
    "else:\n",
    "    # Define discovery and replication cycles\n",
    "    cycles_discovery = ['1999-2000', '2001-2002', '2003-2004', '2005-2006', '2007-2008']\n",
    "    cycles_replicate = ['2009-2010', '2011-2012', '2013-2014', '2015-2016', '2017-2018']\n",
    "\n",
    "    # Filter data for discovery and replication groups\n",
    "    df_nhanes_discovery = df_nhanes[df_nhanes['Cycle'].isin(cycles_discovery)]\n",
    "    df_nhanes_replicate = df_nhanes[df_nhanes['Cycle'].isin(cycles_replicate)]\n",
    "\n",
    "    # Set the oder of cycles\n",
    "    df_nhanes_discovery['Cycle'] = pd.Categorical(df_nhanes_discovery['Cycle'], categories=cycles_discovery, ordered=True)\n",
    "    df_nhanes_replicate['Cycle'] = pd.Categorical(df_nhanes_replicate['Cycle'], categories=cycles_replicate, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrames to keep only the columns of interest\n",
    "df_nhanes_discovery = df_nhanes_discovery[[i_outcome] + list_covariates + list_exposes].dropna(subset=[i_outcome])\n",
    "df_nhanes_replicate = df_nhanes_replicate[[i_outcome] + list_covariates + list_exposes].dropna(subset=[i_outcome])\n",
    "\n",
    "# Sync both DataFrames to have the same Exposure columns\n",
    "# Drop columns with all NaN values in both DataFrames\n",
    "df_nhanes_discovery = df_nhanes_discovery.dropna(axis=1, how='all')\n",
    "df_nhanes_replicate = df_nhanes_replicate.dropna(axis=1, how='all')\n",
    "\n",
    "# get the common columns\n",
    "common_columns = df_nhanes_discovery.columns.intersection(df_nhanes_replicate.columns)\n",
    "\n",
    "# filter both DataFrames to keep only the common columns\n",
    "df_nhanes_discovery = df_nhanes_discovery[common_columns]\n",
    "df_nhanes_replicate = df_nhanes_replicate[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 columns and 11453 rows on discovery dataset\n",
      "301 columns and 12695 rows on replicate dataset\n"
     ]
    }
   ],
   "source": [
    "# check if both groups as the same number of columns\n",
    "n_discovery_exe = len(df_nhanes_discovery.columns)\n",
    "n_replicate_exe = len(df_nhanes_replicate.columns)\n",
    "if n_discovery_exe != n_replicate_exe:\n",
    "    # Raise an error if the number of columns is different\n",
    "    print(f\"Discovery has {n_discovery_exe} columns and Replicate has {n_replicate_exe} columns\")\n",
    "    print(\"Columns in Discovery but not in Replicate:\")\n",
    "    print(set(df_nhanes_discovery.columns) - set(df_nhanes_replicate.columns))\n",
    "    print(\"Columns in Replicate but not in Discovery:\")\n",
    "    print(set(df_nhanes_replicate.columns) - set(df_nhanes_discovery.columns))\n",
    "    print(\"Skipping this outcome\")\n",
    "    # continue\n",
    "    ...\n",
    "print(f\"{n_discovery_exe} columns and {len(df_nhanes_discovery)} rows on discovery dataset\")\n",
    "print(f\"{n_replicate_exe} columns and {len(df_nhanes_replicate)} rows on replicate dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Running categorize\n",
      "--------------------------------------------------------------------------------\n",
      "43 of 301 variables (14.29%) are classified as constant (1 unique value).\n",
      "76 of 301 variables (25.25%) are classified as binary (2 unique values).\n",
      "55 of 301 variables (18.27%) are classified as categorical (3 to 6 unique values).\n",
      "116 of 301 variables (38.54%) are classified as continuous (>= 15 unique values).\n",
      "0 of 301 variables (0.00%) were dropped.\n",
      "11 of 301 variables (3.65%) were not categorized and need to be set manually.\n",
      "\t10 variables had between 6 and 15 unique values\n",
      "\t1 variables had >= 15 values but couldn't be converted to continuous (numeric) values\n",
      "================================================================================\n",
      "================================================================================\n",
      "Running categorize\n",
      "--------------------------------------------------------------------------------\n",
      "41 of 301 variables (13.62%) are classified as constant (1 unique value).\n",
      "89 of 301 variables (29.57%) are classified as binary (2 unique values).\n",
      "39 of 301 variables (12.96%) are classified as categorical (3 to 6 unique values).\n",
      "116 of 301 variables (38.54%) are classified as continuous (>= 15 unique values).\n",
      "0 of 301 variables (0.00%) were dropped.\n",
      "16 of 301 variables (5.32%) were not categorized and need to be set manually.\n",
      "\t15 variables had between 6 and 15 unique values\n",
      "\t1 variables had >= 15 values but couldn't be converted to continuous (numeric) values\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Categories the columns types\n",
    "df_nhanes_discovery = igem.epc.modify.categorize(df_nhanes_discovery)\n",
    "df_nhanes_replicate = igem.epc.modify.categorize(df_nhanes_replicate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug propose: Select two expose factores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: 11 variables need to be categorized into a type manually\u001b[0m\n",
      "\u001b[33mWARNING: 16 variables need to be categorized into a type manually\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Categories the columns types\n",
    "df_nhanes_discovery = igem.epc.describe.get_types(df_nhanes_discovery)\n",
    "df_nhanes_replicate = igem.epc.describe.get_types(df_nhanes_replicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count            301\n",
       "unique             5\n",
       "top       continuous\n",
       "freq             116\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nhanes_discovery.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate percent zero for continuous phenotypes \n",
    "# RETURNS ERROR\n",
    "# df_nhanes_discovery = igem.epc.modify.colfilter_percent_zero(df_nhanes_discovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get skewness values and histogram plots of the phenotypes\n",
    "# RETURNS ERROR\n",
    "# igem.epc.describe.skewness(df_nhanes_discovery, dropna='True')\n",
    "\n",
    "#Plot histogram of phenotype and show skewness values\n",
    "title = f\"Discovery: Skew ADHD Age 1.5-5 = {df_nhanes_discovery['phe-ADHD Pre'].skew(axis = 0, skipna = True):.6}\"\n",
    "igem.epc.plot.histogram(df_nhanes_discovery, column=\"phe-ADHD Pre\", title=title, bins=100)\n",
    "\n",
    "###Log transform all phenotypes since the skewness values are greater than 0.5### \n",
    "dis_pheno_log_transform_pre = igem.epc.modify.transform(df_nhanes_discovery, 'log')\n",
    "\n",
    "\n",
    "igem.epc.describe.skewness(dis_pheno_log_transform_pre, dropna='True')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed with: ALQ140Q and ALQ150\n",
      "11453\n",
      "ALQ140Q  -  ALQ150\n",
      "LBDLDL_N\n",
      "['RIDAGEYR', 'RIAGENDR', 'RIDRETH1', 'BMXBMI', 'Cycle']\n",
      "RIDAGEYR     float64\n",
      "RIAGENDR    category\n",
      "RIDRETH1    category\n",
      "BMXBMI       float64\n",
      "Cycle       category\n",
      "LBDLDL_N     float64\n",
      "ALQ140Q      float64\n",
      "ALQ150      category\n",
      "dtype: object\n",
      "       RIDAGEYR RIAGENDR RIDRETH1  BMXBMI      Cycle  LBDLDL_N  ALQ140Q ALQ150\n",
      "ID                                                                            \n",
      "41479      52.0      1.0      1.0   27.56  2007-2008     121.0      3.0    2.0\n",
      "41485      30.0      2.0      2.0   25.99  2007-2008     119.0      NaN    NaN\n",
      "41486      61.0      2.0      1.0   31.21  2007-2008     110.0      NaN    NaN\n",
      "41487      27.0      1.0      5.0   23.44  2007-2008     105.0      0.0    2.0\n",
      "41489      40.0      2.0      1.0   36.59  2007-2008     106.0      3.0    2.0\n"
     ]
    }
   ],
   "source": [
    "e1 = \"ALQ140Q\"\n",
    "e2 = \"ALQ150\"\n",
    "\n",
    "# Check if columns exist in the DataFrame\n",
    "if columns_exist(df_nhanes_discovery, [e1, e2]):\n",
    "    # create a DataFrame with the columns of interest\n",
    "    df_maintable_exe = df_nhanes_discovery.loc[:, list_covariates + [i_outcome, e1, e2]]\n",
    "    print(f\"Processed with: {e1} and {e2}\")\n",
    "else:\n",
    "    print(f\"Skipped: {e1} and/or {e2} not found\")\n",
    "\n",
    "print(len(df_maintable_exe))\n",
    "print(e1, \" - \", e2)\n",
    "print(i_outcome)\n",
    "print(list_covariates)\n",
    "print(df_maintable_exe.dtypes)\n",
    "print(df_maintable_exe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "InteractionRegression\n",
      "-------------------------\n",
      "Continuous Outcome (family = Gaussian): 'LBDLDL_N'\n",
      "Using 11,453 of 11,453 observations\n",
      "Regressing 2 variables\n",
      "\t0 binary variables\n",
      "\t1 categorical variables\n",
      "\t1 continuous variables\n",
      "\t0 genotypes variables\n",
      "Processing 1 interactions\n",
      "-------------------------\n",
      "\u001b[32mRunning 1 interactions using 14 processes...\u001b[0m\n",
      "\n",
      "\u001b[32m\tFinished Running 1 interactions\u001b[0m\n",
      "\u001b[32m0 tests had an error\u001b[0m\n",
      "Completed Interaction Study for LBDLDL_N\n",
      "\n",
      "Completed association study\n"
     ]
    }
   ],
   "source": [
    "Interation_Study = igem.epc.analyze.interaction_study(\n",
    "        data=df_maintable_exe,\n",
    "        outcomes=i_outcome,\n",
    "        interactions=[(e1, e2)],\n",
    "        covariates=list_covariates,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the loop to process all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_results_discover.append(\n",
    "    [\n",
    "        Interation_Study.LRT_pvalue.index.levels[2][0],\n",
    "        Interation_Study.LRT_pvalue.index.levels[0][0],\n",
    "        Interation_Study.LRT_pvalue.index.levels[1][0],\n",
    "        Interation_Study.Converged.values[0],\n",
    "        Interation_Study.LRT_pvalue.values[0],\n",
    "        Interation_Study.LRT_pvalue.values[0] * len(df_maintable_exe),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the results\n",
    "df_results_discover = pd.DataFrame(\n",
    "    list_results_discover,\n",
    "    columns=[\n",
    "        \"Outcome\", \"Term1\", \"Term2\", \"Converged\", \"LRT_pvalue\", \"Bonfp\"\n",
    "        ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Term1</th>\n",
       "      <th>Term2</th>\n",
       "      <th>Converged</th>\n",
       "      <th>LRT_pvalue</th>\n",
       "      <th>Bonfp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LBDLDL_N</td>\n",
       "      <td>ALQ140Q</td>\n",
       "      <td>ALQ150</td>\n",
       "      <td>True</td>\n",
       "      <td>0.109112</td>\n",
       "      <td>1249.658862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outcome    Term1   Term2  Converged  LRT_pvalue        Bonfp\n",
       "0  LBDLDL_N  ALQ140Q  ALQ150       True    0.109112  1249.658862"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_discover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATORVASTATIN_CALCIUM\", \"SIMVASTATIN\", \"PRAVASTATIN_SODIUM\", \"FLUVASTATIN_SODIUM\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
