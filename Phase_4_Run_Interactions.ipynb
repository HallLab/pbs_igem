{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import igem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path().resolve()\n",
    "path_data = path / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 55,206 observations of 916 variables\n",
      "Start Run Interactions Process with: 55206 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrerico/Works/Projects/pbs_igem/.venv/lib/python3.10/site-packages/clarite/modules/load.py:81: DtypeWarning: Columns (442,869) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(filename, index_col=index_col, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# df_nhanes = pd.read_csv(str(path_data) + \"/step_03_01_nhanes_data.csv\")\n",
    "df_nhanes = igem.epc.load.from_csv(str(path_data) +  \"/step_03_01_nhanes_data.csv\", index_col='sample')\n",
    "print(f\"Start Run Interactions Process with: {len(df_nhanes)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous columns: ['sequence', 'ALQ140Q', 'ALQ150', 'AUQ231', 'BMXBMI', 'CBD620', 'CBQ050', 'DBD060', 'DBD072A', 'DBD072B', 'DBD072C', 'DBD072D', 'DBD072U', 'DBD222B', 'DBD222C', 'DBD222D', 'DBD222U', 'DBQ197', 'DBQ229', 'DBQ235A', 'DBQ235B', 'DBQ235C', 'DBQ925B', 'DUQ250', 'DUQ260', 'DUQ270Q', 'DUQ272', 'DUQ290', 'DUQ300', 'DUQ310Q', 'DUQ330', 'DUQ340', 'DUQ350Q', 'DUQ352', 'DUQ380A', 'DUQ380B', 'DUQ380C', 'DUQ380D', 'ECQ030', 'ECQ040', 'ENQ090', 'GTDSCMMN', 'GTXDRANK', 'HOQ070', 'HOQ080', 'HSQ590', 'LBD4CELC', 'LBDFOL', 'LBDHDD', 'LBDIHGSI', 'LBDLDL', 'LBDRBF', 'LBDV1ALC', 'LBDV1ELC', 'LBDV2CLC', 'LBDV2ELC', 'LBDV2PLC', 'LBDV4CLC', 'LBDVBFLC', 'LBDVCFLC', 'LBDVDBLC', 'LBDVDELC', 'LBDVEBLC', 'LBDVMELC', 'LBDVOXLC', 'LBDVSTLC', 'LBDVTCLC', 'LBDVTOLC', 'LBDVTPLC', 'LBDVXYLC', 'LBDWBFLC', 'LBDWCFLC', 'LBX2DF', 'LBXBCD', 'LBXBPB', 'LBXCOT', 'LBXIHG', 'LBXNM', 'LBXPFBS', 'LBXPFDE', 'LBXPFDO', 'LBXPFOA', 'LBXPFOS', 'LBXPFSA', 'LBXPFUA', 'LBXPLP', 'LBXRBFSI', 'LBXSF2SI', 'LBXTC', 'LBXTHG', 'LBXV1A', 'LBXV1D', 'LBXV1E', 'LBXV2A', 'LBXV2C', 'LBXV2E', 'LBXV2P', 'LBXV2T', 'LBXV3B', 'LBXV4C', 'LBXV4E', 'LBXVBF', 'LBXVBM', 'LBXVBZ', 'LBXVCB', 'LBXVCF', 'LBXVCM', 'LBXVCT', 'LBXVDB', 'LBXVDM', 'LBXVDP', 'LBXVEB', 'LBXVFN', 'LBXVIPB', 'LBXVMC', 'LBXVME', 'LBXVNB', 'LBXVOX', 'LBXVST', 'LBXVTC', 'LBXVTE', 'LBXVTO', 'LBXVXY', 'LBXWBF', 'LBXWBM', 'LBXWCF', 'LBXWCM', 'LBXWME', 'OCQ290G', 'OCQ290Q', 'OHQ660', 'OHQ670', 'OSQ020A', 'OSQ160B', 'RDD040', 'RIDAGEYR', 'RIDRETH1', 'SLD010H', 'SMD030', 'SMD055', 'SMD057', 'SMD100CO', 'SMD100NI', 'SMD410', 'SMD415A', 'SMD430', 'SMD630', 'SMQ020', 'SMQ040', 'SMQ050Q', 'SMQ077', 'SMQ620', 'SMQ660', 'SMQ664M', 'SMQ664O', 'SMQ664W', 'SMQ670', 'SMQ680', 'SMQ690B', 'SMQ690C', 'SMQ690D', 'SMQ690E', 'SMQ690F', 'SMQ710', 'SMQ720', 'SMQ725', 'SMQ740', 'SMQ750', 'SMQ755', 'SMQ770', 'SMQ780', 'SMQ785', 'SMQ800', 'SMQ817', 'SMQ830', 'SMQ840', 'URDAAZLC', 'URDRIMLC', 'URXAAZ', 'URXATZ', 'URXBPH', 'URXCRS', 'URXDAZ', 'URXDEA', 'URXDEE', 'URXDHD', 'URXDTZ', 'URXEQU', 'URXETL', 'URXETU', 'URXGNS', 'URXMAL', 'URXMTM', 'URXMTO', 'URXNAL', 'URXNO3', 'URXOP1', 'URXOP2', 'URXOP3', 'URXOP6', 'URXOPP', 'URXPTU', 'URXSCN', 'URXSISM', 'URXUAB', 'URXUAS', 'URXUAS5', 'URXUBA', 'URXUBE', 'URXUCD', 'URXUCO', 'URXUCR', 'URXUCS', 'URXUHG', 'URXUIO', 'URXUMO', 'URXUP8', 'URXUPB', 'URXUPT', 'URXUSB', 'URXUTL', 'URXUTM', 'URXUTU', 'URXUUR', 'VTQ250A', 'VTQ250B', 'VTQ260B', 'WHD080O', 'WHD080P', 'WHD100O', 'WHD100P', 'ARQ034D', 'ARQ077', 'CBQ800', 'DBQ073A', 'DBQ073B', 'DBQ073C', 'DBQ073D', 'DBQ073E', 'DBQ073U', 'DBQ223A', 'DBQ223B', 'DBQ223C', 'DBQ223D', 'DBQ223E', 'DBQ223U', 'DEQ038Q', 'DUQ219', 'LBDNMLC', 'LBDVDXLC', 'LBXSBU', 'LBXSCA', 'LBXSCR', 'LBXSGL', 'LBXSIR', 'LBXSKSI', 'LBXSPH', 'LBXSTB', 'LBXSTR', 'LBXSUA', 'LBXV06', 'URDTIME1', 'URDTIME2', 'URDTIME3', 'URDUCR2S', 'URXAMU', 'URXUCR2', 'DIQ175I', 'DMDHHSZA', 'LBDBCOSI', 'LBDBCRSI', 'LBDBMNLC', 'LBDBMNSI', 'LBDBSELC', 'LBDBSESI', 'LBDFORLC', 'LBDFOT', 'LBDPFL', 'LBDRFO', 'LBDRFOSI', 'LBDSZNSI', 'LBDVFTLC', 'LBDVVBLC', 'LBDWFL', 'LBXACR', 'LBXBCO', 'LBXBCR', 'LBXBFOA', 'LBXBGE', 'LBXBGM', 'LBXBMN', 'LBXBSE', 'LBXEOA', 'LBXFOR', 'LBXSCU', 'LBXSSE', 'LBXSZN', 'LBXV07N', 'LBXV08N', 'LBXVBZN', 'LBXVC6', 'LBXVDEE', 'LBXVEA', 'LBXVEC', 'LBXVIBN', 'LBXVMCP', 'LBXVTHF', 'OHQ571Q', 'OHQ571U', 'OHQ576G', 'OHQ576Q', 'OHQ576U', 'SLD012', 'SMD460', 'SMD470', 'SMDANY', 'SMQ078', 'SMQ621', 'SMQ661', 'SMQ681', 'SMQ690G', 'SMQ690H', 'SMQ690I', 'SMQ690J', 'SMQ845', 'SMQ848', 'SMQ849', 'SMQ851', 'SMQ852Q', 'SMQ857', 'SMQ861', 'SMQ863', 'SMQ925', 'SMQ930', 'SMQ935', 'SSBCEP', 'SSBCPP', 'SSDBUP', 'SSDBZP', 'SSDCP', 'SSGLYP', 'URDANBLC', 'URDANTLC', 'URDCOXLC', 'URDNCTLC', 'URDNICLC', 'URDNOXLC', 'URDUIOLC', 'URXANBT', 'URXANTT', 'URXBPF', 'URXBPS', 'URXCOTT', 'URXCOXT', 'URXHCTT', 'URXNICT', 'URXNNCT', 'URXNOXT', 'URXUFL', 'URXUMN', 'URXUSN', 'URXUSR', 'VTQ233A', 'VTQ233B', 'WTSH2YR', 'BIDTBW', 'BIXC005K', 'CIQD028', 'DBD197', 'DBQ071A', 'DBQ071B', 'DBQ071C', 'DBQ071D', 'DBQ071U', 'DBQ221B', 'DBQ221C', 'DBQ221D', 'DBQ221U', 'DCDSTAT', 'DCQ160', 'DCQ250', 'DED038Q', 'DR1IB12A', 'DR1ICAFF', 'DR1ICALC', 'DR1ICARB', 'DR1ICOPP', 'DR1IFA', 'DR1IFDFE', 'DR1IFF', 'DR1IFIBE', 'DR1IFOLA', 'DR1IIRON', 'DR1ILYCO', 'DR1IMAGN', 'DR1IPHOS', 'DR1IPOTA', 'DR1ISELE', 'DR1ISODI', 'DR1ISUGR', 'DR1IVB12', 'DR1IZINC', 'DR2IB12A', 'DR2ICAFF', 'DR2ICALC', 'DR2ICARB', 'DR2ICOPP', 'DR2IFA', 'DR2IFDFE', 'DR2IFF', 'DR2IFIBE', 'DR2IFOLA', 'DR2IIRON', 'DR2ILYCO', 'DR2IMAGN', 'DR2IPHOS', 'DR2IPOTA', 'DR2ISELE', 'DR2ISODI', 'DR2ISUGR', 'DR2IVB12', 'DR2IZINC', 'DUQ100', 'LBDB12SI', 'LBDD3LC', 'LBDDFSLC', 'LBDDWSLC', 'LBDFOLSI', 'LBDRBFSI', 'LBXALD', 'LBXALDLA', 'LBXB12', 'LBXBR1', 'LBXBR1LA', 'LBXBR2', 'LBXBR2LA', 'LBXBR3', 'LBXBR3LA', 'LBXBR4', 'LBXBR5', 'LBXBR6', 'LBXBR66', 'LBXBR7', 'LBXBR8', 'LBXDIE', 'LBXDIELA', 'LBXDX2', 'LBXFOL', 'LBXHDD', 'LBXHPE', 'LBXHPELA', 'LBXIRN', 'LBXLCC', 'LBXLZ1', 'LBXLZ2', 'LBXME2', 'LBXML1', 'LBXMMA', 'LBXMR1', 'LBXMR2', 'LBXRBF', 'LBXSEL', 'LBXTIB', 'LBXV4T', 'MCQ270', 'MCQ290', 'OHQ095', 'SMD070', 'SMD130', 'SMD160', 'SMD220', 'SMD235', 'SMQ140', 'SMQ143', 'SMQ170', 'SMQ210', 'SMQ640', 'SMQ650', 'SSAR1_N', 'SSARA_N', 'SSDHA_N', 'SSED1_N', 'SSEN1_N', 'SSEPA_N', 'SSLG1_N', 'SSLNA_N', 'SSML1_N', 'SSMR1_N', 'SSNR1_N', 'SSOL1_N', 'SSPL1_N', 'SSPM1_N', 'SSST1_N', 'URXPCP', 'AADEXSTS', 'LBXDWS', 'LBXDWT', 'LBXIF2', 'LBXWIO', 'LBXWNO', 'LBXWP8', 'WTAL2YR', 'CSQ241', 'LBDAR1LC', 'LBDARALC', 'LBDDHALC', 'LBDDP3LC', 'LBDDP6LC', 'LBDED1LC', 'LBDEN1LC', 'LBDEPALC', 'LBDLG1LC', 'LBDLNALC', 'LBDML1LC', 'LBDMMALC', 'LBDMR1LC', 'LBDMRGLC', 'LBDNR1LC', 'LBDOL1LC', 'LBDPENLC', 'LBDPL1LC', 'LBDPM1LC', 'LBDST1LC', 'LBX10AL', 'LBX4AL', 'LBXAR1', 'LBXARA', 'LBXBZAL', 'LBXCAP', 'LBXDHA', 'LBXDP3', 'LBXDP6', 'LBXED1', 'LBXEN1', 'LBXEPA', 'LBXLAR', 'LBXLG1', 'LBXLNA', 'LBXMMASI', 'LBXMRG', 'LBXNR1', 'LBXOL1', 'LBXPEN', 'LBXPL1', 'LBXPM1', 'LBXSD1', 'LBXST1', 'OHQ565', 'OHQ570Q', 'OHQ570U', 'OHQ575G', 'OHQ575Q', 'OHQ575U', 'OHQ580', 'OHQ585Q', 'OHQ585U', 'OHQ590G', 'OHQ590Q', 'OHQ590U', 'SSDOCP', 'SSDOCPL', 'SSDPCP', 'SSFPEA', 'SSFPEAL', 'SSNFLH', 'SSNPFOS', 'SSNPFOSL', 'SSPFBS', 'SSPFBSL', 'SSPFSA', 'SSPFSAL', 'SSPFUA', 'SSPFUAL', 'SSSNFL', 'URX1NP', 'URX2NP', 'URX4BP', 'URXANS', 'URXDMN', 'URXHM', 'URXNAB', 'URXNAT', 'URXNHM', 'URXNNN', 'URXOTD', 'DBD070J', 'DBD195', 'DBD220J', 'DBD235A', 'DBD235B', 'DBD235C', 'DBQ070A', 'DBQ070B', 'DBQ070C', 'DBQ070D', 'DBQ120', 'DBQ220B', 'DBQ220C', 'DBQ220D', 'HRDHG', 'HRXHG', 'KIQ320', 'LBDCOTSI', 'LBDHDL', 'LBDV3ALC', 'LBXLA', 'LBXLACL', 'LBXV3A', 'LBXZBZ', 'LBXZCF', 'LBXZEB', 'LBXZTO', 'OHQ090', 'RDQ040', 'SMD690A', 'SMD690B', 'SMD690C', 'SMD690D', 'SMD690F', 'SMD710', 'SMD720', 'SMD740', 'SMD750', 'SMD770', 'SMD780', 'SMD800', 'SMD830', 'URXALA', 'VTQ060', 'VTQ200G', 'VTQ200H', 'ALQ142', 'DSD010AN', 'DSDANCNT', 'DSQTCAFF', 'DSQTCALC', 'DSQTCARB', 'DSQTCOPP', 'DSQTFA', 'DSQTFDFE', 'DSQTFIBE', 'DSQTIODI', 'DSQTIRON', 'DSQTLYCO', 'DSQTMAGN', 'DSQTPHOS', 'DSQTPOTA', 'DSQTSELE', 'DSQTSODI', 'DSQTSUGR', 'DSQTVB12', 'DSQTZINC', 'DUD380F', 'LBDBGESI', 'LBDBGMSI', 'LBDTIB', 'LBXUIB', 'LBXVMIK', 'SLD013', 'SMQ690K', 'SMQ857O', 'URXBCEP', 'URXBCPP', 'URXBDCP', 'URXDBUP', 'URXUCM', 'URXUNI', 'DBD071A', 'DBD071B', 'DBD071C', 'DBD071D', 'DBD071U', 'DBD196', 'DBD221B', 'DBD221C', 'DBD221D', 'DBD221U', 'DBD229', 'DBD235AE', 'DBD235BE', 'DBD235CE', 'LB2COT', 'LB2FOL', 'LB2GLU', 'LB2MMA', 'LB2RBF', 'LB2SCA', 'LB2SGL', 'LB2SUA', 'LBDSCR', 'LBDSTB', 'SSFER', 'SSXNO3', 'SSXSCN', 'SSXUP8', 'URXMET', 'WTUIO2YR']\n",
      "Categorical columns: ['Cycle', 'SMD100BR', 'SLQ300', 'SLQ320']\n",
      "Binary columns: ['DBD222A', 'LBD2DFLC', 'LBDCOTLC', 'LBDIHGLC', 'LBDPFBSL', 'LBDPFDEL', 'LBDPFDOL', 'LBDPFOAL', 'LBDPFOSL', 'LBDPFSAL', 'LBDPFUAL', 'LBDSF2LC', 'LBDTHGLC', 'LBDV1DLC', 'LBDV2ALC', 'LBDV2TLC', 'LBDV3BLC', 'LBDV4ELC', 'LBDVBMLC', 'LBDVBZLC', 'LBDVCBLC', 'LBDVCMLC', 'LBDVCTLC', 'LBDVDMLC', 'LBDVDPLC', 'LBDVFNLC', 'LBDVHELC', 'LBDVIPLC', 'LBDVMCLC', 'LBDVNBLC', 'LBDVTELC', 'LBDWBMLC', 'LBDWCMLC', 'LBDWMELC', 'LBX4CE', 'LBXVDE', 'LBXVHE', 'LBXVTP', 'PHQ020', 'RIAGENDR', 'SMD100MN', 'SMQ664B', 'SMQ664C', 'SMQ690A', 'SPQ100', 'URDATZLC', 'URDBPHLC', 'URDDAZLC', 'URDDEALC', 'URDDEELC', 'URDDTZLC', 'URDEQULC', 'URDETLLC', 'URDETULC', 'URDGNSLC', 'URDMALLC', 'URDMTMLC', 'URDMTOLC', 'URDNO3LC', 'URDOP1LC', 'URDOP2LC', 'URDOP3LC', 'URDOP6LC', 'URDOPPLC', 'URDPTULC', 'URDSCNLC', 'URDSISLC', 'URDUA5LC', 'URDUABLC', 'URDUASLC', 'URDUBALC', 'URDUBELC', 'URDUCDLC', 'URDUCOLC', 'URDUCSLC', 'URDUMOLC', 'URDUP8LC', 'URDUPBLC', 'URDUSBLC', 'URDUTMLC', 'URDUTULC', 'URDUURLC', 'URXRIM', 'URXSIS', 'WHD080M', 'WHD100M', 'LBDBCDLC', 'LBDBPBLC', 'LBDV06LC', 'LBXVDX', 'URDMU1LC', 'URDMU2LC', 'URDMU3LC', 'URDMU4LC', 'URDMU5LC', 'URDMU6LC', 'URDMU7LC', 'URDMX1LC', 'URDMX2LC', 'URDMX3LC', 'URDMX4LC', 'URDMX5LC', 'URDMX6LC', 'URDMX7LC', 'LBDACRLC', 'LBDBCOLC', 'LBDBCRLC', 'LBDBFOAL', 'LBDBGELC', 'LBDBGMLC', 'LBDEOALC', 'LBDHCTLC', 'LBDPFLLC', 'LBDV07LC', 'LBDV08LC', 'LBDVC6LC', 'LBDVEALC', 'LBDVECLC', 'LBDVEELC', 'LBDVHTLC', 'LBDVIBLC', 'LBDVMPLC', 'LBDVZBLC', 'LBDWFLLC', 'LBXVTFT', 'LBXVVB', 'SSBCEPL', 'SSBCPPL', 'SSBPPPL', 'SSDBUPL', 'SSDBZPL', 'SSDCPL', 'SSGLYPL', 'SSIPPPL', 'URDBPFLC', 'URDBPSLC', 'URDCOTLC', 'URDHCTLC', 'URDUCRLC', 'URDUFLLC', 'URDUHGLC', 'URDUSNLC', 'URDUSRLC', 'URXUTRI', 'DBQ221A', 'LBDALDLC', 'LBDBR1LC', 'LBDBR2LC', 'LBDBR3LC', 'LBDBR4LC', 'LBDBR5LC', 'LBDBR66C', 'LBDBR6LC', 'LBDBR7LC', 'LBDBR8LC', 'LBDBR9LC', 'LBDDIELC', 'LBDHPELC', 'LBDV4TLC', 'LBXDX1', 'LBXETD', 'LBXME1', 'LBXTSS', 'RHQ551A', 'URDPCPLC', 'LBDIF2LC', 'LBDWIOLC', 'LBDWNOLC', 'LBDWP8LC', 'LBD10ALC', 'LBD4ALC', 'LBDBZLC', 'LBDCAPLC', 'LBDLARLC', 'LBDSD1LC', 'SDNPFOSL', 'SSDPCPL', 'SSNFLL', 'SSNFOS', 'SSNFOSL', 'URD1NPLC', 'URD2NPLC', 'URD4BPLC', 'URDANSLC', 'URDDMNLC', 'URDHMLC', 'URDNHMLC', 'URDOTDLC', 'DBQ220A', 'HRDHGLC', 'HRDHGLC2', 'LBDZBZLC', 'LBDZCFLC', 'LBDZEBLC', 'LBDZTOLC', 'OCQ330A', 'SMD680', 'URDALALC', 'VTQ140', 'VTQ170', 'VTQ200L', 'CBQ845', 'LBDLCCLC', 'LBDSTBLC', 'LBDUIBLC', 'LBDVMKLC', 'URDBCPLC', 'URDCEPLC', 'URDDUPLC', 'URDUCMLC', 'URDUNILC', 'DBD221A', 'LB2COTLC', 'URDMETLC', 'Gender']\n"
     ]
    }
   ],
   "source": [
    "# # Função para categorizar colunas automaticamente\n",
    "# def categorize_columns(df):\n",
    "#     continuous = []\n",
    "#     categorical = []\n",
    "#     binary = []\n",
    "    \n",
    "#     for col in df.columns:\n",
    "#         unique_values = df[col].dropna().unique()  # Valores únicos não nulos\n",
    "#         num_unique_values = len(unique_values)\n",
    "        \n",
    "#         if pd.api.types.is_numeric_dtype(df[col]):\n",
    "#             if num_unique_values == 2:\n",
    "#                 binary.append(col)\n",
    "#             else:\n",
    "#                 continuous.append(col)\n",
    "#         else:\n",
    "#             if num_unique_values == 2:\n",
    "#                 binary.append(col)\n",
    "#             else:\n",
    "#                 categorical.append(col)\n",
    "    \n",
    "#     return continuous, categorical, binary\n",
    "\n",
    "# # Executa a função para categorizar as colunas\n",
    "# continuous_cols, categorical_cols, binary_cols = categorize_columns(df_nhanes)\n",
    "\n",
    "# # Exibe os resultados\n",
    "# print(f\"Continuous columns: {continuous_cols}\")\n",
    "# print(f\"Categorical columns: {categorical_cols}\")\n",
    "# print(f\"Binary columns: {binary_cols}\")\n",
    "\n",
    "# # Ajusta os tipos de colunas no DataFrame\n",
    "# for col in continuous_cols:\n",
    "#     df_nhanes[col] = df_nhanes[col].astype(float)\n",
    "\n",
    "# for col in categorical_cols:\n",
    "#     df_nhanes[col] = df_nhanes[col].astype('category')\n",
    "\n",
    "# for col in binary_cols:\n",
    "#     df_nhanes[col] = df_nhanes[col].astype('category')  # Pode usar boolean se preferir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparer Models from Interactions IGEM GE.filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 992,923 observations of 5 variables\n",
      "Start with: 992923 interactions\n"
     ]
    }
   ],
   "source": [
    "# Read Moldel (we need to clean interactions that is not in coluns list)\n",
    "df_model = igem.epc.load.from_csv(str(path_data) + \"/step_01_05_Models.csv\") \n",
    "# pd.read_csv(str(path_data) + \"/step_01_05_Models.csv\")\n",
    "print(f\"Start with: {len(df_model)} interactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Running colfilter\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWARNING: 5 variables need to be categorized into a type manually\u001b[0m\n",
      "Keeping 2 of 5 variables:\n",
      "\t0 of 0 binary variables\n",
      "\t0 of 0 categorical variables\n",
      "\t0 of 0 continuous variables\n",
      "\t2 of 5 unknown variables\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "df_model = igem.epc.modify.colfilter(\n",
    "    df_model,\n",
    "    only=['field_name_1', 'field_name_2']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now has 213059 interactions after filtering\n"
     ]
    }
   ],
   "source": [
    "# Keep only interactions that are in the columns of df_nhanes\n",
    "# Create a set of df_nhanes columns for quick checking\n",
    "nhanes_columns = set(df_nhanes.columns)\n",
    "# filter df_models to keep only interactions where both terms are in df_nhanes columns\n",
    "df_models_filtered = df_model[df_model.apply(lambda row: row['field_name_1'] in nhanes_columns and row['field_name_2'] in nhanes_columns, axis=1)]\n",
    "print(f\"Now has {len(df_models_filtered)} interactions after filtering\")\n",
    "df_models_filtered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field_name_1</th>\n",
       "      <th>field_name_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LBDLG1LC</td>\n",
       "      <td>ARQ077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LBDLG1LC</td>\n",
       "      <td>ARQ034D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LBXLG1</td>\n",
       "      <td>ARQ077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LBXLG1</td>\n",
       "      <td>ARQ034D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSLG1_N</td>\n",
       "      <td>ARQ077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213054</th>\n",
       "      <td>LBDSZNSI</td>\n",
       "      <td>SMD830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213055</th>\n",
       "      <td>LBDSZNSI</td>\n",
       "      <td>SMD770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213056</th>\n",
       "      <td>LBDSZNSI</td>\n",
       "      <td>SMD800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213057</th>\n",
       "      <td>LBDSZNSI</td>\n",
       "      <td>SMD740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213058</th>\n",
       "      <td>LBDSZNSI</td>\n",
       "      <td>BIXC005K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213059 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       field_name_1 field_name_2\n",
       "0          LBDLG1LC       ARQ077\n",
       "1          LBDLG1LC      ARQ034D\n",
       "2            LBXLG1       ARQ077\n",
       "3            LBXLG1      ARQ034D\n",
       "4           SSLG1_N       ARQ077\n",
       "...             ...          ...\n",
       "213054     LBDSZNSI       SMD830\n",
       "213055     LBDSZNSI       SMD770\n",
       "213056     LBDSZNSI       SMD800\n",
       "213057     LBDSZNSI       SMD740\n",
       "213058     LBDSZNSI     BIXC005K\n",
       "\n",
       "[213059 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Cohorts\n",
    "\n",
    "good = HDL - Have 3 diff types of metrics ()\n",
    "\n",
    "bad = LDL, Total-C and Triglycerides split in Discovery (1999-2008) and Replicate (2009-2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slipt the data into discovery and replicate in bad group \n",
    "cycles_discovery = ['1999-2000', '2001-2002', '2003-2004', '2005-2006', '2007-2008']\n",
    "cycles_replicate = ['2009-2010', '2011-2012', '2013-2014', '2015-2016', '2017-2018']\n",
    "\n",
    "df_nhanes_discovery = df_nhanes[df_nhanes['Cycle'].isin(cycles_discovery)]\n",
    "df_nhanes_replicate = df_nhanes[df_nhanes['Cycle'].isin(cycles_replicate)]\n",
    "\n",
    "df_nhanes_discovery['Cycle'] = pd.Categorical(df_nhanes_discovery['Cycle'], categories=cycles_discovery, ordered=True)\n",
    "df_nhanes_replicate['Cycle'] = pd.Categorical(df_nhanes_replicate['Cycle'], categories=cycles_replicate, ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Interactions Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_covariates = ['RIDAGEYR', 'RIAGENDR', 'RIDRETH1', 'BMXBMI', 'Cycle']\n",
    "list_bad_phenotypes = ['LBDLDL', 'LBXTC', 'LBXSTR']\n",
    "list_good_phenotypes = ['LBDHDL', 'LBXHDD', 'LBDHDD']\n",
    "\n",
    "excluded_columns = set(list_covariates + list_bad_phenotypes + list_good_phenotypes)\n",
    "list_exposes = [col for col in df_nhanes.columns if col not in excluded_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT:\n",
    "\n",
    "#### before run, we need to ajust cholesterol by who use some medication to control.\n",
    "#### How to check if both group has the same fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para verificar se as colunas existem no DataFrame\n",
    "def columns_exist(df, cols):\n",
    "    return all(col in df.columns for col in cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to collect results\n",
    "df_results_discover_final = pd.DataFrame()\n",
    "df_results_replicate_final = pd.DataFrame()\n",
    "list_results_discover = []\n",
    "list_results_replicate = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will only run it for the LDL phenotype to test the script's integrity.\n",
    "\n",
    "Important: we still need to define the rationale for adjusting participants who use medications to control cholesterol.\n",
    "\n",
    "- Nikki and I are evaluating the use of stalin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with: LBDLDL\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Defines Discovery and Replicate groups based on cycles.\n",
    "Aligns both groups to have the same exposure factors.\n",
    "\n",
    "Important: In production, this block is inside the phenotype loop.\n",
    "\"\"\"\n",
    "\n",
    "list_bad_phenotypes = ['LBDLDL',]\n",
    "for i_outcome in list_bad_phenotypes:\n",
    "    print(f\"Start with: {i_outcome}\")\n",
    "\n",
    "    # Filter the DataFrames to keep only the columns of interest\n",
    "    df_nhanes_discovery_exe = df_nhanes_discovery[[i_outcome] + list_covariates + list_exposes].dropna(subset=[i_outcome])\n",
    "    df_nhanes_replicate_exe = df_nhanes_replicate[[i_outcome] + list_covariates + list_exposes].dropna(subset=[i_outcome])\n",
    "\n",
    "    # Sync both DataFrames to have the same Exposure columns\n",
    "    # Drop columns with all NaN values in both DataFrames\n",
    "    df_nhanes_discovery_exe = df_nhanes_discovery_exe.dropna(axis=1, how='all')\n",
    "    df_nhanes_replicate_exe = df_nhanes_replicate_exe.dropna(axis=1, how='all')\n",
    "    # get the common columns\n",
    "    common_columns = df_nhanes_discovery_exe.columns.intersection(df_nhanes_replicate_exe.columns)\n",
    "    # filter both DataFrames to keep only the common columns\n",
    "    df_nhanes_discovery_exe = df_nhanes_discovery_exe[common_columns]\n",
    "    df_nhanes_replicate_exe = df_nhanes_replicate_exe[common_columns]\n",
    "    # check if both groups as the same number of columns\n",
    "    n_discovery_exe = len(df_nhanes_discovery_exe.columns)\n",
    "    n_replicate_exe = len(df_nhanes_replicate_exe.columns)\n",
    "    # Raise an error if the number of columns is different\n",
    "    if n_discovery_exe != n_replicate_exe:\n",
    "        print(f\"Discovery has {n_discovery_exe} columns and Replicate has {n_replicate_exe} columns\")\n",
    "        print(\"Columns in Discovery but not in Replicate:\")\n",
    "        print(set(df_nhanes_discovery_exe.columns) - set(df_nhanes_replicate_exe.columns))\n",
    "        print(\"Columns in Replicate but not in Discovery:\")\n",
    "        print(set(df_nhanes_replicate_exe.columns) - set(df_nhanes_discovery_exe.columns))\n",
    "        print(\"Skipping this outcome\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 are continuous columns: ['LBDLDL', 'RIDAGEYR', 'RIDRETH1', 'BMXBMI', 'ALQ140Q', 'ALQ150', 'AUQ231', 'CBD620', 'CBQ050', 'DBQ197', 'DBQ229', 'DBQ235A', 'DBQ235B', 'DBQ235C', 'DUQ250', 'DUQ260', 'DUQ270Q', 'DUQ272', 'DUQ290', 'DUQ300', 'DUQ310Q', 'DUQ330', 'DUQ340', 'DUQ350Q', 'DUQ352', 'DUQ380A', 'ENQ090', 'GTDSCMMN', 'GTXDRANK', 'HOQ070', 'HOQ080', 'HSQ590', 'LBDFOL', 'LBDIHGSI', 'LBDRBF', 'LBDV4CLC', 'LBDVBFLC', 'LBDVCFLC', 'LBDVDBLC', 'LBDVEBLC', 'LBDVMELC', 'LBDVOXLC', 'LBDVSTLC', 'LBDVTCLC', 'LBDVTOLC', 'LBDVXYLC', 'LBDWBFLC', 'LBDWCFLC', 'LBX2DF', 'LBXBCD', 'LBXBPB', 'LBXCOT', 'LBXIHG', 'LBXNM', 'LBXPFBS', 'LBXPFDE', 'LBXPFDO', 'LBXPFOA', 'LBXPFOS', 'LBXPFSA', 'LBXPFUA', 'LBXPLP', 'LBXRBFSI', 'LBXSF2SI', 'LBXTHG', 'LBXV1D', 'LBXV2A', 'LBXV2P', 'LBXV2T', 'LBXV3B', 'LBXV4C', 'LBXVBF', 'LBXVBM', 'LBXVBZ', 'LBXVCF', 'LBXVCM', 'LBXVCT', 'LBXVDB', 'LBXVDM', 'LBXVDP', 'LBXVEB', 'LBXVFN', 'LBXVIPB', 'LBXVMC', 'LBXVME', 'LBXVNB', 'LBXVOX', 'LBXVST', 'LBXVTC', 'LBXVTE', 'LBXVTO', 'LBXVXY', 'LBXWBF', 'LBXWBM', 'LBXWCF', 'LBXWCM', 'LBXWME', 'OCQ290G', 'OCQ290Q', 'OSQ020A', 'RDD040', 'SLD010H', 'SMD030', 'SMD055', 'SMD057', 'SMD100CO', 'SMD100NI', 'SMD410', 'SMD415A', 'SMD430', 'SMD630', 'SMQ020', 'SMQ040', 'SMQ050Q', 'SMQ077', 'SMQ620', 'SMQ660', 'SMQ664M', 'SMQ664O', 'SMQ670', 'SMQ680', 'SMQ710', 'SMQ720', 'SMQ725', 'SMQ740', 'SMQ750', 'SMQ755', 'SMQ770', 'SMQ780', 'SMQ785', 'SMQ800', 'SMQ817', 'SMQ830', 'SMQ840', 'URXBPH', 'URXCRS', 'URXDAZ', 'URXDEA', 'URXDEE', 'URXDHD', 'URXEQU', 'URXETL', 'URXGNS', 'URXMAL', 'URXNAL', 'URXNO3', 'URXOP1', 'URXOP2', 'URXOP3', 'URXOP6', 'URXOPP', 'URXSCN', 'URXUAB', 'URXUAS', 'URXUAS5', 'URXUBA', 'URXUBE', 'URXUCD', 'URXUCO', 'URXUCR', 'URXUCS', 'URXUHG', 'URXUIO', 'URXUMO', 'URXUP8', 'URXUPB', 'URXUPT', 'URXUSB', 'URXUTL', 'URXUTM', 'URXUTU', 'URXUUR', 'VTQ250A', 'VTQ250B', 'VTQ260B', 'LBXSBU', 'LBXSCA', 'LBXSCR', 'LBXSGL', 'LBXSIR', 'LBXSKSI', 'LBXSPH', 'LBXSTB', 'LBXSUA', 'LBXACR', 'LBDB12SI', 'LBXB12', 'LBXIRN', 'LBXLCC', 'LBXML1', 'LBDTIB']\n",
      "2 are categorical columns: ['Cycle', 'SMD100BR']\n",
      "65 are binary columns: ['RIAGENDR', 'LBD2DFLC', 'LBDCOTLC', 'LBDIHGLC', 'LBDPFBSL', 'LBDPFDEL', 'LBDPFDOL', 'LBDPFOAL', 'LBDPFOSL', 'LBDPFSAL', 'LBDPFUAL', 'LBDSF2LC', 'LBDTHGLC', 'LBDV2ALC', 'LBDVBMLC', 'LBDVBZLC', 'LBDVCMLC', 'LBDVCTLC', 'LBDVDMLC', 'LBDVDPLC', 'LBDVFNLC', 'LBDVIPLC', 'LBDVMCLC', 'LBDVNBLC', 'LBDVTELC', 'LBDWBMLC', 'LBDWCMLC', 'LBDWMELC', 'PHQ020', 'SMD100MN', 'SMQ664C', 'SPQ100', 'URDBPHLC', 'URDDAZLC', 'URDDEALC', 'URDDEELC', 'URDEQULC', 'URDETLLC', 'URDGNSLC', 'URDMALLC', 'URDNO3LC', 'URDOP1LC', 'URDOP2LC', 'URDOP3LC', 'URDOP6LC', 'URDOPPLC', 'URDSCNLC', 'URDUA5LC', 'URDUABLC', 'URDUASLC', 'URDUBALC', 'URDUBELC', 'URDUCDLC', 'URDUCOLC', 'URDUMOLC', 'URDUPBLC', 'URDUSBLC', 'URDUTMLC', 'URDUTULC', 'URDUURLC', 'WHD080M', 'WHD100M', 'LBDACRLC', 'URDUHGLC', 'Gender']\n",
      "43 are columns to drop with constant value: ['sequence', 'DBQ925B', 'DUQ380B', 'DUQ380C', 'DUQ380D', 'LBD4CELC', 'LBDV1ALC', 'LBDV1DLC', 'LBDV1ELC', 'LBDV2CLC', 'LBDV2ELC', 'LBDV2PLC', 'LBDV2TLC', 'LBDV3BLC', 'LBDV4ELC', 'LBDVCBLC', 'LBDVDELC', 'LBDVHELC', 'LBDVTPLC', 'LBX4CE', 'LBXV1A', 'LBXV1E', 'LBXV2C', 'LBXV2E', 'LBXV4E', 'LBXVCB', 'LBXVDE', 'LBXVHE', 'LBXVTP', 'OSQ160B', 'SMQ690A', 'SMQ690B', 'SMQ690C', 'SMQ690D', 'SMQ690E', 'SMQ690F', 'URDUCSLC', 'URDUP8LC', 'WHD080O', 'WHD080P', 'WHD100O', 'WHD100P', 'LBXMR1']\n",
      "================================================================================\n",
      "Running make_continuous\n",
      "--------------------------------------------------------------------------------\n",
      "Set 191 of 258 variable(s) as continuous, each with 11,453 observations\n",
      "================================================================================\n",
      "================================================================================\n",
      "Running make_categorical\n",
      "--------------------------------------------------------------------------------\n",
      "Set 2 of 258 variable(s) as categorical, each with 11,453 observations\n",
      "================================================================================\n",
      "================================================================================\n",
      "Running make_categorical\n",
      "--------------------------------------------------------------------------------\n",
      "Set 65 of 258 variable(s) as categorical, each with 11,453 observations\n",
      "================================================================================\n",
      "================================================================================\n",
      "Running make_categorical\n",
      "--------------------------------------------------------------------------------\n",
      "Set 2 of 258 variable(s) as categorical, each with 11,453 observations\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Performs the categorization of the analysis components. For constant columns, we will eliminate them.\n",
    "\"\"\"\n",
    "\n",
    "def categorize_columns(df):\n",
    "    continuous = []\n",
    "    categorical = []\n",
    "    binary = []\n",
    "    columns_to_drop = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].dropna().unique()\n",
    "        num_unique_values = len(unique_values)\n",
    "        \n",
    "        if num_unique_values == 1:\n",
    "            # add the column to the list of columns to remove\n",
    "            columns_to_drop.append(col)\n",
    "\n",
    "        elif pd.api.types.is_numeric_dtype(df[col]):\n",
    "            if num_unique_values == 2:\n",
    "                # binary.append(col)\n",
    "                continuous.append(col)\n",
    "            else:\n",
    "                continuous.append(col)\n",
    "        else:\n",
    "            if num_unique_values == 2:\n",
    "                binary.append(col)\n",
    "            else:\n",
    "                categorical.append(col)\n",
    "    \n",
    "    return continuous, categorical, binary, columns_to_drop\n",
    "\n",
    "# run the function to categorize the columns\n",
    "continuous_cols, categorical_cols, binary_cols, columns_to_drop = categorize_columns(df_nhanes_discovery_exe)\n",
    "\n",
    "# show the results\n",
    "print(f\"{len(continuous_cols)} are continuous columns: {continuous_cols}\")\n",
    "print(f\"{len(categorical_cols)} are categorical columns: {categorical_cols}\")\n",
    "print(f\"{len(binary_cols)} are binary columns: {binary_cols}\")\n",
    "print(f\"{len(columns_to_drop)} are columns to drop with constant value: {columns_to_drop}\")\n",
    "\n",
    "# remove the columns with only one unique value\n",
    "df_nhanes_discovery_exe.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "df_nhanes_discovery_exe = igem.epc.modify.make_continuous(\n",
    "    df_nhanes_discovery_exe,\n",
    "    only=continuous_cols\n",
    ")\n",
    "\n",
    "df_nhanes_discovery_exe = igem.epc.modify.make_categorical(\n",
    "    df_nhanes_discovery_exe,\n",
    "    only=categorical_cols\n",
    ")\n",
    "\n",
    "df_nhanes_discovery_exe = igem.epc.modify.make_categorical(\n",
    "    df_nhanes_discovery_exe,\n",
    "    only=binary_cols\n",
    ")\n",
    "\n",
    "# Manually set columns\n",
    "df_nhanes_discovery_exe = igem.epc.modify.make_categorical(\n",
    "    df_nhanes_discovery_exe,\n",
    "    only=[\"RIDRETH1\", \"Cycle\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug propose: Select two expose factores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed with: ALQ140Q and ALQ150\n",
      "11453\n",
      "ALQ140Q  -  ALQ150\n",
      "LBDLDL\n",
      "['RIDAGEYR', 'RIAGENDR', 'RIDRETH1', 'BMXBMI', 'Cycle']\n",
      "RIDAGEYR     float64\n",
      "RIAGENDR    category\n",
      "RIDRETH1    category\n",
      "BMXBMI       float64\n",
      "Cycle       category\n",
      "LBDLDL       float64\n",
      "ALQ140Q      float64\n",
      "ALQ150       float64\n",
      "dtype: object\n",
      "         RIDAGEYR RIAGENDR RIDRETH1  BMXBMI      Cycle  LBDLDL  ALQ140Q  \\\n",
      "ID                                                                        \n",
      "41479.0      52.0      1.0      1.0   27.56  2007-2008   121.0      3.0   \n",
      "41485.0      30.0      2.0      2.0   25.99  2007-2008   119.0      NaN   \n",
      "41486.0      61.0      2.0      1.0   31.21  2007-2008   110.0      NaN   \n",
      "41487.0      27.0      1.0      5.0   23.44  2007-2008   105.0      0.0   \n",
      "41489.0      40.0      2.0      1.0   36.59  2007-2008   106.0      3.0   \n",
      "\n",
      "         ALQ150  \n",
      "ID               \n",
      "41479.0     2.0  \n",
      "41485.0     NaN  \n",
      "41486.0     NaN  \n",
      "41487.0     2.0  \n",
      "41489.0     2.0  \n"
     ]
    }
   ],
   "source": [
    "e1 = \"ALQ140Q\"\n",
    "e2 = \"ALQ150\"\n",
    "\n",
    "# Check if columns exist in the DataFrame\n",
    "if columns_exist(df_nhanes_discovery_exe, [e1, e2]):\n",
    "    # create a DataFrame with the columns of interest\n",
    "    df_maintable_exe = df_nhanes_discovery_exe.loc[:, list_covariates + [i_outcome, e1, e2]]\n",
    "    print(f\"Processed with: {e1} and {e2}\")\n",
    "else:\n",
    "    print(f\"Skipped: {e1} and/or {e2} not found\")\n",
    "\n",
    "print(len(df_maintable_exe))\n",
    "print(e1, \" - \", e2)\n",
    "print(i_outcome)\n",
    "print(list_covariates)\n",
    "print(df_maintable_exe.dtypes)\n",
    "print(df_maintable_exe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "InteractionRegression\n",
      "-------------------------\n",
      "Continuous Outcome (family = Gaussian): 'LBDLDL'\n",
      "Using 11,453 of 11,453 observations\n",
      "Regressing 2 variables\n",
      "\t0 binary variables\n",
      "\t0 categorical variables\n",
      "\t2 continuous variables\n",
      "\t0 genotypes variables\n",
      "Processing 1 interactions\n",
      "-------------------------\n",
      "\u001b[32mRunning 1 interactions using 14 processes...\u001b[0m\n",
      "\n",
      "\u001b[32m\tFinished Running 1 interactions\u001b[0m\n",
      "\u001b[32m0 tests had an error\u001b[0m\n",
      "Completed Interaction Study for LBDLDL\n",
      "\n",
      "Completed association study\n"
     ]
    }
   ],
   "source": [
    "Interation_Study = igem.epc.analyze.interaction_study(\n",
    "        data=df_maintable_exe,\n",
    "        outcomes=i_outcome,\n",
    "        interactions=[(e1, e2)],\n",
    "        covariates=list_covariates,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the loop to process all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for terms in df_models_filtered.itertuples():\n",
    "\n",
    "# e1 = terms.field_name_1\n",
    "# e2 = terms.field_name_2\n",
    "# print(f\"Start with: {e1} and {e2}\")\n",
    "\n",
    "e1 = \"URDUP8LC\"\n",
    "e2 = \"OSQ160B\"\n",
    "\n",
    "# Verifica se as colunas e1 e e2 existem no DataFrame\n",
    "if columns_exist(df_nhanes_discovery_exe, [e1, e2]):\n",
    "    # Cria o DataFrame df_maintable_exe apenas se ambas as colunas existirem\n",
    "    df_maintable_exe = df_nhanes_discovery_exe.loc[:, list_covariates + [i_outcome, e1, e2]]\n",
    "    # Faça o processamento necessário com df_maintable_exe\n",
    "    print(f\"Processed with: {e1} and {e2}\")\n",
    "else:\n",
    "    print(f\"Skipped: {e1} and/or {e2} not found\")\n",
    "    ...\n",
    "\n",
    "print(len(df_maintable_exe))\n",
    "\n",
    "# # Run Interation Study\n",
    "# Interation_Study = igem.epc.analyze.interaction_study(\n",
    "#     data=df_maintable_exe,\n",
    "#     outcomes=i_outcome,\n",
    "#     interactions=[(e1, e2)],\n",
    "#     covariates=list_covariates,\n",
    "# )\n",
    "Interation_Study = igem.analyze.interaction_study(\n",
    "        data=df_maintable_exe,\n",
    "        outcomes=i_outcome,\n",
    "        interactions=[(e1, e2)],\n",
    "        covariates=list_covariates,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "#     # Save results in list: outcome/e1/e2/converged/LRT_pvalue/Bonfp\n",
    "#     list_results_discover.append(\n",
    "#         [\n",
    "#             Interation_Study.LRT_pvalue.index.levels[2][0],\n",
    "#             Interation_Study.LRT_pvalue.index.levels[0][0],\n",
    "#             Interation_Study.LRT_pvalue.index.levels[1][0],\n",
    "#             Interation_Study.Converged.values[0],\n",
    "#             Interation_Study.LRT_pvalue.values[0],\n",
    "#             Interation_Study.LRT_pvalue.values[0] * len(df_maintable_exe),\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "# # Create a DataFrame with the results\n",
    "# df_results_discover = pd.DataFrame(\n",
    "#     list_results_discover,\n",
    "#     columns=[\n",
    "#         \"Outcome\", \"Term1\", \"Term2\", \"Converged\", \"LRT_pvalue\", \"Bonfp\"\n",
    "#         ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATORVASTATIN_CALCIUM\", \"SIMVASTATIN\", \"PRAVASTATIN_SODIUM\", \"FLUVASTATIN_SODIUM\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
