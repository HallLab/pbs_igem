{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Create the Interaction Pairs\n",
    "\n",
    "Documentation: https://halllab.atlassian.net/wiki/spaces/IGEM/pages/67862529/Phase+2+Create+the+Interaction+Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successfully loading all data from the 1999 to 2018 NHANES cycles into the MyNHANES system, we progress to the next phase which involves compiling a comprehensive list of fields related to exposure factors. We will utilize the detailed descriptions of these NHANES fields to operate the IGEM Search Engine, facilitating the retrieval of relevant TERMS and enabling thorough consultation of the existing relationships within our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the path to the data folder\n",
    "path = Path().resolve()\n",
    "path_data = path / 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 02_00: Extract Fields List from MyNHANES\n",
    "\n",
    "no code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 02_01: Search IGEM Terms from NHANES Fields Description\n",
    "\n",
    "no code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 02_02: Identify Exposure Factor Fields\n",
    "\n",
    "no code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 02_03: Generate Parameters File to setting the filter to GE.db database\n",
    "\n",
    "no code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 02_04: Obtaining the Terms of Relationship \n",
    "\n",
    "no code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 02_05: Filter Interactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from previous steps\n",
    "df_terms = pd.read_csv(\n",
    "    str(path_data) + \"/step_02_04_TermsRelationship.csv\"\n",
    "    )\n",
    "ls_terms = pd.read_excel(\n",
    "    (str(path_data) + \"/step_02_02_Exposes_Identification.xlsx\"),\n",
    "    sheet_name=\"Exposes_Terms_Uniques\",\n",
    "    header=None,\n",
    "    names=['term']\n",
    "    )['term'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrerico/Works/Projects/pbs_igem/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "/Users/andrerico/Works/Projects/pbs_igem/.venv/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Filter the terms relationship\n",
    "df_terms_filtered = df_terms[\n",
    "    df_terms['term_1'].isin(ls_terms) & df_terms['term_2'].isin(ls_terms)\n",
    "    ]\n",
    "df_terms_filtered.drop(\n",
    "    columns=[\n",
    "        'datasource',\n",
    "        'connector',\n",
    "        'qtd_links'\n",
    "        ],\n",
    "    inplace=True\n",
    "    )\n",
    "\n",
    "df_terms_filtered.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save the data\n",
    "df_terms_filtered.to_csv(\n",
    "    str(path_data) + \"/step_02_05_TermsRelationship_filtered.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 02_06: Link the IGEM Terms to NHANES Field ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read NHANES data and IGEM terms\n",
    "df_NHAMES_fields = pd.read_excel(\n",
    "    str(path_data) + \"/step_02_00_MyNHANES_fields_list.xlsx\",\n",
    "    sheet_name=\"fields_unique\"\n",
    "    )\n",
    "df_NHANES_terms = pd.read_csv(\n",
    "    str(path_data) + \"/step_02_01_word_to_term.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of string fields for comparison\n",
    "df_NHAMES_fields['field_description'] = df_NHAMES_fields['field_description'].str.lower().str.strip()\n",
    "df_NHANES_terms['string'] = df_NHANES_terms['string'].str.lower().str.strip()\n",
    "\n",
    "# Concat the DataFrames based on the 'string' column of df_NHANES_terms and 'field_description' of df_NHANES_fields\n",
    "df_NHANES_fields_terms = pd.merge(df_NHANES_terms, df_NHAMES_fields, left_on='string', right_on='field_description', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns 'datasource', 'connector' and 'qtd_links'\n",
    "df_NHANES_fields_terms.drop(columns=['row', 'string', 'word', 'term_id', 'term_descr', 'qtd_terms', 'qtd_loops', 'time'], inplace=True)\n",
    "\n",
    "# Drop duplicates records\n",
    "df_NHANES_fields_terms.drop_duplicates(inplace=True)\n",
    "df_NHANES_fields_terms.dropna(subset=['term'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_1</th>\n",
       "      <th>term_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25911</th>\n",
       "      <td>chem:d012906</td>\n",
       "      <td>dise:d013471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71399</th>\n",
       "      <td>chem:d000073893</td>\n",
       "      <td>go:0030431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76760</th>\n",
       "      <td>chem:d002241</td>\n",
       "      <td>go:0030431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94162</th>\n",
       "      <td>chem:d010710</td>\n",
       "      <td>go:0030431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102837</th>\n",
       "      <td>chem:d013256</td>\n",
       "      <td>go:0030431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219915</th>\n",
       "      <td>meta:hmdb0014344</td>\n",
       "      <td>meta:hmdb0302501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220415</th>\n",
       "      <td>meta:hmdb0015043</td>\n",
       "      <td>meta:hmdb0015517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220557</th>\n",
       "      <td>meta:hmdb0015043</td>\n",
       "      <td>meta:hmdb0302501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220980</th>\n",
       "      <td>meta:hmdb0015517</td>\n",
       "      <td>meta:hmdb0302501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221041</th>\n",
       "      <td>meta:hmdb0015532</td>\n",
       "      <td>meta:hmdb0302501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1243 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  term_1            term_2\n",
       "25911       chem:d012906      dise:d013471\n",
       "71399    chem:d000073893        go:0030431\n",
       "76760       chem:d002241        go:0030431\n",
       "94162       chem:d010710        go:0030431\n",
       "102837      chem:d013256        go:0030431\n",
       "...                  ...               ...\n",
       "219915  meta:hmdb0014344  meta:hmdb0302501\n",
       "220415  meta:hmdb0015043  meta:hmdb0015517\n",
       "220557  meta:hmdb0015043  meta:hmdb0302501\n",
       "220980  meta:hmdb0015517  meta:hmdb0302501\n",
       "221041  meta:hmdb0015532  meta:hmdb0302501\n",
       "\n",
       "[1243 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean terms interactions df column\n",
    "df_interactions= df_terms_filtered.drop(columns=['term_group_1', 'term_category_1', 'word_1',  'description_1', 'term_group_2', 'term_category_2', 'word_2', 'description_2'])\n",
    "print(df_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DataFrame\n",
    "new_rows = []\n",
    "\n",
    "for _, model_row in df_interactions.iterrows():\n",
    "    term_1 = model_row['term_1']\n",
    "    term_2 = model_row['term_2']\n",
    "    \n",
    "    # Searching for matches for term_1\n",
    "    term_1_matches = df_NHANES_fields_terms[df_NHANES_fields_terms['term'] == term_1]\n",
    "    \n",
    "    # Searching for matches for term_2\n",
    "    term_2_matches = df_NHANES_fields_terms[df_NHANES_fields_terms['term'] == term_2]\n",
    "    \n",
    "    for _, term_1_row in term_1_matches.iterrows():\n",
    "        for _, term_2_row in term_2_matches.iterrows():\n",
    "            new_row = {\n",
    "                'term_1': term_1,\n",
    "                'field_name_1': term_1_row['field_name'],\n",
    "                'field_description_1': term_1_row['field_description'],\n",
    "                'term_2': term_2,\n",
    "                'field_name_2': term_2_row['field_name'],\n",
    "                'field_description_2': term_2_row['field_description']\n",
    "            }\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "df_models = pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save interactions nhanes exposes in the models file\n",
    "df_models.to_csv(\n",
    "    str(path_data) + \"/step_02_06_Models.csv\",\n",
    "    index=False\n",
    "    )\n",
    "print(len(df_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 02_07: Create a NHANES Fields List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the fields in a unique list\n",
    "# This list will used the select parameters in the NHANES API\n",
    "df_fields_1 = df_models.drop(columns=['term_1', 'term_2', 'field_name_2', 'field_description_2'])\n",
    "df_fields_2 = df_models.drop(columns=['term_1', 'term_2', 'field_name_1', 'field_description_1'])\n",
    "df_fields_1.rename(columns={'field_name_1': 'field_name', 'field_description_1': 'field_description'}, inplace=True)\n",
    "df_fields_2.rename(columns={'field_name_2': 'field_name', 'field_description_2': 'field_description'}, inplace=True)\n",
    "df_fields = pd.concat([df_fields_1, df_fields_2], ignore_index=True)\n",
    "df_fields.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the Phenotypes and Covariants fields\n",
    "phen_cov = {\n",
    "    'field_name': [\n",
    "        'LBDHDL',\n",
    "        'LBXHDD',\n",
    "        'LBDHDD',\n",
    "        'LBDLDL',\n",
    "        'LBXTC',\n",
    "        'LBXSTR',\n",
    "        'RIAGENDR',\n",
    "        'RIDAGEYR',\n",
    "        'BMXBMI',\n",
    "        'RIDRETH1'\n",
    "    ],\n",
    "    'field_description': [\n",
    "        'HDL-cholesterol (mg/dL)',\n",
    "        'Direct HDL-Cholesterol (mg/dL)',\n",
    "        'Direct HDL-Cholesterol (mg/dL)',\n",
    "        'LDL-cholesterol (mg/dL)',\n",
    "        'Total Cholesterol (mg/dL)',\n",
    "        'Triglycerides (mg/dL)',\n",
    "        'Gender',\n",
    "        'Age in years at screening',\n",
    "        'Body Mass Index (kg/m**2)',\n",
    "        'Race/Ethnicity - Recode',\n",
    "    ]\n",
    "}\n",
    "\n",
    "new_rows = pd.DataFrame(phen_cov)\n",
    "\n",
    "# Concatenate Phenotypes, Covariants and Exposures fields\n",
    "df_fields = pd.concat([new_rows, df_fields], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fields file\n",
    "df_fields.to_csv(\n",
    "    str(path_data) + \"/step_02_07_Fields.csv\",\n",
    "    index=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
